{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 200,
  "global_step": 23450,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.021326508850501174,
      "grad_norm": 4.405858993530273,
      "learning_rate": 2.993731343283582e-05,
      "loss": 2.0016,
      "step": 50
    },
    {
      "epoch": 0.04265301770100235,
      "grad_norm": 3.6021831035614014,
      "learning_rate": 2.9873347547974415e-05,
      "loss": 1.751,
      "step": 100
    },
    {
      "epoch": 0.06397952655150352,
      "grad_norm": 3.5417189598083496,
      "learning_rate": 2.9809381663113005e-05,
      "loss": 1.5868,
      "step": 150
    },
    {
      "epoch": 0.0853060354020047,
      "grad_norm": 4.82362174987793,
      "learning_rate": 2.97454157782516e-05,
      "loss": 1.4849,
      "step": 200
    },
    {
      "epoch": 0.0853060354020047,
      "eval_loss": 1.3586865663528442,
      "eval_runtime": 2.0528,
      "eval_samples_per_second": 481.284,
      "eval_steps_per_second": 60.404,
      "step": 200
    },
    {
      "epoch": 0.10663254425250586,
      "grad_norm": 4.3676066398620605,
      "learning_rate": 2.968144989339019e-05,
      "loss": 1.4362,
      "step": 250
    },
    {
      "epoch": 0.12795905310300704,
      "grad_norm": 4.4056572914123535,
      "learning_rate": 2.9617484008528787e-05,
      "loss": 1.4954,
      "step": 300
    },
    {
      "epoch": 0.1492855619535082,
      "grad_norm": 4.158863067626953,
      "learning_rate": 2.9553518123667376e-05,
      "loss": 1.4447,
      "step": 350
    },
    {
      "epoch": 0.1706120708040094,
      "grad_norm": 3.3899965286254883,
      "learning_rate": 2.9489552238805972e-05,
      "loss": 1.3845,
      "step": 400
    },
    {
      "epoch": 0.1706120708040094,
      "eval_loss": 1.236436128616333,
      "eval_runtime": 2.1276,
      "eval_samples_per_second": 464.367,
      "eval_steps_per_second": 58.281,
      "step": 400
    },
    {
      "epoch": 0.19193857965451055,
      "grad_norm": 3.5013511180877686,
      "learning_rate": 2.9425586353944562e-05,
      "loss": 1.4121,
      "step": 450
    },
    {
      "epoch": 0.21326508850501172,
      "grad_norm": 3.2113680839538574,
      "learning_rate": 2.9361620469083158e-05,
      "loss": 1.2968,
      "step": 500
    },
    {
      "epoch": 0.2345915973555129,
      "grad_norm": 3.7624948024749756,
      "learning_rate": 2.9297654584221748e-05,
      "loss": 1.3978,
      "step": 550
    },
    {
      "epoch": 0.2559181062060141,
      "grad_norm": 2.8498055934906006,
      "learning_rate": 2.9233688699360344e-05,
      "loss": 1.3928,
      "step": 600
    },
    {
      "epoch": 0.2559181062060141,
      "eval_loss": 1.1822032928466797,
      "eval_runtime": 2.1518,
      "eval_samples_per_second": 459.143,
      "eval_steps_per_second": 57.625,
      "step": 600
    },
    {
      "epoch": 0.27724461505651526,
      "grad_norm": 4.4862589836120605,
      "learning_rate": 2.9169722814498933e-05,
      "loss": 1.2491,
      "step": 650
    },
    {
      "epoch": 0.2985711239070164,
      "grad_norm": 2.824458360671997,
      "learning_rate": 2.910575692963753e-05,
      "loss": 1.252,
      "step": 700
    },
    {
      "epoch": 0.3198976327575176,
      "grad_norm": 3.0271451473236084,
      "learning_rate": 2.904179104477612e-05,
      "loss": 1.2903,
      "step": 750
    },
    {
      "epoch": 0.3412241416080188,
      "grad_norm": 3.47902774810791,
      "learning_rate": 2.8977825159914715e-05,
      "loss": 1.3668,
      "step": 800
    },
    {
      "epoch": 0.3412241416080188,
      "eval_loss": 1.142547607421875,
      "eval_runtime": 2.1347,
      "eval_samples_per_second": 462.833,
      "eval_steps_per_second": 58.088,
      "step": 800
    },
    {
      "epoch": 0.3625506504585199,
      "grad_norm": 3.5060486793518066,
      "learning_rate": 2.8913859275053305e-05,
      "loss": 1.3136,
      "step": 850
    },
    {
      "epoch": 0.3838771593090211,
      "grad_norm": 4.102542400360107,
      "learning_rate": 2.88498933901919e-05,
      "loss": 1.288,
      "step": 900
    },
    {
      "epoch": 0.4052036681595223,
      "grad_norm": 2.5773391723632812,
      "learning_rate": 2.878592750533049e-05,
      "loss": 1.316,
      "step": 950
    },
    {
      "epoch": 0.42653017701002344,
      "grad_norm": 3.387356996536255,
      "learning_rate": 2.8721961620469087e-05,
      "loss": 1.1575,
      "step": 1000
    },
    {
      "epoch": 0.42653017701002344,
      "eval_loss": 1.1316790580749512,
      "eval_runtime": 2.1373,
      "eval_samples_per_second": 462.273,
      "eval_steps_per_second": 58.018,
      "step": 1000
    },
    {
      "epoch": 0.44785668586052463,
      "grad_norm": 2.456104278564453,
      "learning_rate": 2.8657995735607676e-05,
      "loss": 1.1996,
      "step": 1050
    },
    {
      "epoch": 0.4691831947110258,
      "grad_norm": 3.6483030319213867,
      "learning_rate": 2.859402985074627e-05,
      "loss": 1.2889,
      "step": 1100
    },
    {
      "epoch": 0.49050970356152696,
      "grad_norm": 9.517772674560547,
      "learning_rate": 2.8530063965884862e-05,
      "loss": 1.2217,
      "step": 1150
    },
    {
      "epoch": 0.5118362124120281,
      "grad_norm": 2.4362752437591553,
      "learning_rate": 2.8466098081023455e-05,
      "loss": 1.2585,
      "step": 1200
    },
    {
      "epoch": 0.5118362124120281,
      "eval_loss": 1.1096644401550293,
      "eval_runtime": 2.1403,
      "eval_samples_per_second": 461.628,
      "eval_steps_per_second": 57.937,
      "step": 1200
    },
    {
      "epoch": 0.5331627212625293,
      "grad_norm": 3.5838544368743896,
      "learning_rate": 2.8402132196162047e-05,
      "loss": 1.2794,
      "step": 1250
    },
    {
      "epoch": 0.5544892301130305,
      "grad_norm": 2.9094250202178955,
      "learning_rate": 2.833816631130064e-05,
      "loss": 1.2073,
      "step": 1300
    },
    {
      "epoch": 0.5758157389635317,
      "grad_norm": 2.2772769927978516,
      "learning_rate": 2.8274200426439233e-05,
      "loss": 1.2149,
      "step": 1350
    },
    {
      "epoch": 0.5971422478140328,
      "grad_norm": 3.482492446899414,
      "learning_rate": 2.8210234541577826e-05,
      "loss": 1.2014,
      "step": 1400
    },
    {
      "epoch": 0.5971422478140328,
      "eval_loss": 1.0966336727142334,
      "eval_runtime": 2.1284,
      "eval_samples_per_second": 464.2,
      "eval_steps_per_second": 58.26,
      "step": 1400
    },
    {
      "epoch": 0.618468756664534,
      "grad_norm": 3.7066681385040283,
      "learning_rate": 2.814626865671642e-05,
      "loss": 1.2479,
      "step": 1450
    },
    {
      "epoch": 0.6397952655150352,
      "grad_norm": 3.651480197906494,
      "learning_rate": 2.808230277185501e-05,
      "loss": 1.1457,
      "step": 1500
    },
    {
      "epoch": 0.6611217743655363,
      "grad_norm": 3.0418450832366943,
      "learning_rate": 2.8018336886993604e-05,
      "loss": 1.2408,
      "step": 1550
    },
    {
      "epoch": 0.6824482832160376,
      "grad_norm": 2.913891553878784,
      "learning_rate": 2.7954371002132194e-05,
      "loss": 1.1963,
      "step": 1600
    },
    {
      "epoch": 0.6824482832160376,
      "eval_loss": 1.080464243888855,
      "eval_runtime": 2.1439,
      "eval_samples_per_second": 460.844,
      "eval_steps_per_second": 57.839,
      "step": 1600
    },
    {
      "epoch": 0.7037747920665387,
      "grad_norm": 8.138223648071289,
      "learning_rate": 2.789040511727079e-05,
      "loss": 1.1815,
      "step": 1650
    },
    {
      "epoch": 0.7251013009170398,
      "grad_norm": 3.312202215194702,
      "learning_rate": 2.782643923240938e-05,
      "loss": 1.1027,
      "step": 1700
    },
    {
      "epoch": 0.7464278097675411,
      "grad_norm": 3.685157299041748,
      "learning_rate": 2.7762473347547976e-05,
      "loss": 1.1881,
      "step": 1750
    },
    {
      "epoch": 0.7677543186180422,
      "grad_norm": 3.60745906829834,
      "learning_rate": 2.7698507462686565e-05,
      "loss": 1.153,
      "step": 1800
    },
    {
      "epoch": 0.7677543186180422,
      "eval_loss": 1.0787842273712158,
      "eval_runtime": 2.1189,
      "eval_samples_per_second": 466.277,
      "eval_steps_per_second": 58.521,
      "step": 1800
    },
    {
      "epoch": 0.7890808274685434,
      "grad_norm": 2.6464083194732666,
      "learning_rate": 2.763454157782516e-05,
      "loss": 1.0609,
      "step": 1850
    },
    {
      "epoch": 0.8104073363190446,
      "grad_norm": 3.148099899291992,
      "learning_rate": 2.757057569296375e-05,
      "loss": 1.2278,
      "step": 1900
    },
    {
      "epoch": 0.8317338451695457,
      "grad_norm": 4.504921913146973,
      "learning_rate": 2.7506609808102347e-05,
      "loss": 1.2136,
      "step": 1950
    },
    {
      "epoch": 0.8530603540200469,
      "grad_norm": 3.3289263248443604,
      "learning_rate": 2.7442643923240937e-05,
      "loss": 1.213,
      "step": 2000
    },
    {
      "epoch": 0.8530603540200469,
      "eval_loss": 1.063859224319458,
      "eval_runtime": 2.1228,
      "eval_samples_per_second": 465.431,
      "eval_steps_per_second": 58.414,
      "step": 2000
    },
    {
      "epoch": 0.8743868628705481,
      "grad_norm": 3.2194318771362305,
      "learning_rate": 2.7378678038379533e-05,
      "loss": 1.1358,
      "step": 2050
    },
    {
      "epoch": 0.8957133717210493,
      "grad_norm": 3.4525392055511475,
      "learning_rate": 2.7314712153518122e-05,
      "loss": 1.2106,
      "step": 2100
    },
    {
      "epoch": 0.9170398805715504,
      "grad_norm": 4.112133979797363,
      "learning_rate": 2.725074626865672e-05,
      "loss": 1.1076,
      "step": 2150
    },
    {
      "epoch": 0.9383663894220516,
      "grad_norm": 2.89544415473938,
      "learning_rate": 2.7186780383795308e-05,
      "loss": 1.1013,
      "step": 2200
    },
    {
      "epoch": 0.9383663894220516,
      "eval_loss": 1.0616650581359863,
      "eval_runtime": 2.1311,
      "eval_samples_per_second": 463.603,
      "eval_steps_per_second": 58.185,
      "step": 2200
    },
    {
      "epoch": 0.9596928982725528,
      "grad_norm": 4.815910339355469,
      "learning_rate": 2.7122814498933904e-05,
      "loss": 1.0988,
      "step": 2250
    },
    {
      "epoch": 0.9810194071230539,
      "grad_norm": 3.1037161350250244,
      "learning_rate": 2.7058848614072494e-05,
      "loss": 1.1531,
      "step": 2300
    },
    {
      "epoch": 1.00213265088505,
      "grad_norm": 4.245304584503174,
      "learning_rate": 2.699488272921109e-05,
      "loss": 1.1344,
      "step": 2350
    },
    {
      "epoch": 1.0234591597355513,
      "grad_norm": 4.211191177368164,
      "learning_rate": 2.693091684434968e-05,
      "loss": 1.2019,
      "step": 2400
    },
    {
      "epoch": 1.0234591597355513,
      "eval_loss": 1.0501203536987305,
      "eval_runtime": 2.1414,
      "eval_samples_per_second": 461.375,
      "eval_steps_per_second": 57.905,
      "step": 2400
    },
    {
      "epoch": 1.0447856685860524,
      "grad_norm": 3.840174913406372,
      "learning_rate": 2.6866950959488276e-05,
      "loss": 1.0548,
      "step": 2450
    },
    {
      "epoch": 1.0661121774365536,
      "grad_norm": 2.9081077575683594,
      "learning_rate": 2.6802985074626865e-05,
      "loss": 1.1236,
      "step": 2500
    },
    {
      "epoch": 1.0874386862870549,
      "grad_norm": 2.531442165374756,
      "learning_rate": 2.673901918976546e-05,
      "loss": 1.026,
      "step": 2550
    },
    {
      "epoch": 1.108765195137556,
      "grad_norm": 3.147636890411377,
      "learning_rate": 2.667505330490405e-05,
      "loss": 1.073,
      "step": 2600
    },
    {
      "epoch": 1.108765195137556,
      "eval_loss": 1.0543646812438965,
      "eval_runtime": 2.1418,
      "eval_samples_per_second": 461.304,
      "eval_steps_per_second": 57.896,
      "step": 2600
    },
    {
      "epoch": 1.1300917039880571,
      "grad_norm": 2.216609001159668,
      "learning_rate": 2.6611087420042647e-05,
      "loss": 1.1197,
      "step": 2650
    },
    {
      "epoch": 1.1514182128385584,
      "grad_norm": 2.136227607727051,
      "learning_rate": 2.6547121535181236e-05,
      "loss": 1.0968,
      "step": 2700
    },
    {
      "epoch": 1.1727447216890594,
      "grad_norm": 2.8675482273101807,
      "learning_rate": 2.6483155650319833e-05,
      "loss": 1.1632,
      "step": 2750
    },
    {
      "epoch": 1.1940712305395607,
      "grad_norm": 2.945875406265259,
      "learning_rate": 2.6419189765458422e-05,
      "loss": 1.0631,
      "step": 2800
    },
    {
      "epoch": 1.1940712305395607,
      "eval_loss": 1.0451430082321167,
      "eval_runtime": 2.1321,
      "eval_samples_per_second": 463.394,
      "eval_steps_per_second": 58.159,
      "step": 2800
    },
    {
      "epoch": 1.215397739390062,
      "grad_norm": 3.9761033058166504,
      "learning_rate": 2.635522388059702e-05,
      "loss": 1.0964,
      "step": 2850
    },
    {
      "epoch": 1.236724248240563,
      "grad_norm": 3.144186019897461,
      "learning_rate": 2.6291257995735608e-05,
      "loss": 1.1017,
      "step": 2900
    },
    {
      "epoch": 1.2580507570910642,
      "grad_norm": 2.4654695987701416,
      "learning_rate": 2.6227292110874204e-05,
      "loss": 1.0716,
      "step": 2950
    },
    {
      "epoch": 1.2793772659415654,
      "grad_norm": 3.429943084716797,
      "learning_rate": 2.6163326226012794e-05,
      "loss": 1.0945,
      "step": 3000
    },
    {
      "epoch": 1.2793772659415654,
      "eval_loss": 1.0366848707199097,
      "eval_runtime": 2.1535,
      "eval_samples_per_second": 458.788,
      "eval_steps_per_second": 57.581,
      "step": 3000
    },
    {
      "epoch": 1.3007037747920664,
      "grad_norm": 2.7223258018493652,
      "learning_rate": 2.609936034115139e-05,
      "loss": 1.1431,
      "step": 3050
    },
    {
      "epoch": 1.3220302836425677,
      "grad_norm": 2.984501361846924,
      "learning_rate": 2.603539445628998e-05,
      "loss": 1.1073,
      "step": 3100
    },
    {
      "epoch": 1.343356792493069,
      "grad_norm": 2.202089786529541,
      "learning_rate": 2.5971428571428575e-05,
      "loss": 1.0485,
      "step": 3150
    },
    {
      "epoch": 1.36468330134357,
      "grad_norm": 3.258544683456421,
      "learning_rate": 2.5907462686567165e-05,
      "loss": 1.161,
      "step": 3200
    },
    {
      "epoch": 1.36468330134357,
      "eval_loss": 1.0335850715637207,
      "eval_runtime": 2.1302,
      "eval_samples_per_second": 463.802,
      "eval_steps_per_second": 58.21,
      "step": 3200
    },
    {
      "epoch": 1.3860098101940712,
      "grad_norm": 3.244891405105591,
      "learning_rate": 2.5843496801705754e-05,
      "loss": 1.0505,
      "step": 3250
    },
    {
      "epoch": 1.4073363190445725,
      "grad_norm": 3.1966097354888916,
      "learning_rate": 2.577953091684435e-05,
      "loss": 1.0545,
      "step": 3300
    },
    {
      "epoch": 1.4286628278950735,
      "grad_norm": 2.1909377574920654,
      "learning_rate": 2.571556503198294e-05,
      "loss": 1.1487,
      "step": 3350
    },
    {
      "epoch": 1.4499893367455747,
      "grad_norm": 2.818868398666382,
      "learning_rate": 2.5651599147121536e-05,
      "loss": 1.1082,
      "step": 3400
    },
    {
      "epoch": 1.4499893367455747,
      "eval_loss": 1.028281331062317,
      "eval_runtime": 2.1204,
      "eval_samples_per_second": 465.958,
      "eval_steps_per_second": 58.481,
      "step": 3400
    },
    {
      "epoch": 1.471315845596076,
      "grad_norm": 2.1584010124206543,
      "learning_rate": 2.5587633262260126e-05,
      "loss": 1.0898,
      "step": 3450
    },
    {
      "epoch": 1.492642354446577,
      "grad_norm": 2.3177406787872314,
      "learning_rate": 2.5523667377398722e-05,
      "loss": 1.1807,
      "step": 3500
    },
    {
      "epoch": 1.5139688632970782,
      "grad_norm": 2.770048141479492,
      "learning_rate": 2.545970149253731e-05,
      "loss": 1.0955,
      "step": 3550
    },
    {
      "epoch": 1.5352953721475795,
      "grad_norm": 2.8415122032165527,
      "learning_rate": 2.5395735607675908e-05,
      "loss": 1.0469,
      "step": 3600
    },
    {
      "epoch": 1.5352953721475795,
      "eval_loss": 1.0320650339126587,
      "eval_runtime": 2.1383,
      "eval_samples_per_second": 462.051,
      "eval_steps_per_second": 57.99,
      "step": 3600
    },
    {
      "epoch": 1.5566218809980805,
      "grad_norm": 2.2408952713012695,
      "learning_rate": 2.5331769722814497e-05,
      "loss": 1.1815,
      "step": 3650
    },
    {
      "epoch": 1.5779483898485818,
      "grad_norm": 3.3060686588287354,
      "learning_rate": 2.5267803837953093e-05,
      "loss": 1.082,
      "step": 3700
    },
    {
      "epoch": 1.599274898699083,
      "grad_norm": 3.9967095851898193,
      "learning_rate": 2.5203837953091683e-05,
      "loss": 1.1731,
      "step": 3750
    },
    {
      "epoch": 1.620601407549584,
      "grad_norm": 2.828732490539551,
      "learning_rate": 2.513987206823028e-05,
      "loss": 1.0053,
      "step": 3800
    },
    {
      "epoch": 1.620601407549584,
      "eval_loss": 1.020973563194275,
      "eval_runtime": 2.2067,
      "eval_samples_per_second": 447.724,
      "eval_steps_per_second": 56.192,
      "step": 3800
    },
    {
      "epoch": 1.6419279164000853,
      "grad_norm": 2.5883872509002686,
      "learning_rate": 2.507590618336887e-05,
      "loss": 1.0593,
      "step": 3850
    },
    {
      "epoch": 1.6632544252505865,
      "grad_norm": 3.7760746479034424,
      "learning_rate": 2.5011940298507465e-05,
      "loss": 1.1139,
      "step": 3900
    },
    {
      "epoch": 1.6845809341010876,
      "grad_norm": 2.5918469429016113,
      "learning_rate": 2.4947974413646054e-05,
      "loss": 1.1132,
      "step": 3950
    },
    {
      "epoch": 1.7059074429515888,
      "grad_norm": 2.3682470321655273,
      "learning_rate": 2.488400852878465e-05,
      "loss": 1.0472,
      "step": 4000
    },
    {
      "epoch": 1.7059074429515888,
      "eval_loss": 1.0238229036331177,
      "eval_runtime": 2.1301,
      "eval_samples_per_second": 463.827,
      "eval_steps_per_second": 58.213,
      "step": 4000
    },
    {
      "epoch": 1.72723395180209,
      "grad_norm": 4.342891693115234,
      "learning_rate": 2.482004264392324e-05,
      "loss": 1.1167,
      "step": 4050
    },
    {
      "epoch": 1.748560460652591,
      "grad_norm": 2.7877659797668457,
      "learning_rate": 2.4756076759061836e-05,
      "loss": 1.1196,
      "step": 4100
    },
    {
      "epoch": 1.7698869695030923,
      "grad_norm": 3.0540192127227783,
      "learning_rate": 2.4692110874200426e-05,
      "loss": 1.0865,
      "step": 4150
    },
    {
      "epoch": 1.7912134783535936,
      "grad_norm": 2.7609941959381104,
      "learning_rate": 2.4628144989339022e-05,
      "loss": 1.048,
      "step": 4200
    },
    {
      "epoch": 1.7912134783535936,
      "eval_loss": 1.0169519186019897,
      "eval_runtime": 2.1585,
      "eval_samples_per_second": 457.735,
      "eval_steps_per_second": 57.449,
      "step": 4200
    },
    {
      "epoch": 1.8125399872040946,
      "grad_norm": 2.1977360248565674,
      "learning_rate": 2.456417910447761e-05,
      "loss": 1.0689,
      "step": 4250
    },
    {
      "epoch": 1.8338664960545958,
      "grad_norm": 3.2335894107818604,
      "learning_rate": 2.4500213219616207e-05,
      "loss": 1.1707,
      "step": 4300
    },
    {
      "epoch": 1.855193004905097,
      "grad_norm": 2.581515312194824,
      "learning_rate": 2.4436247334754797e-05,
      "loss": 1.1423,
      "step": 4350
    },
    {
      "epoch": 1.8765195137555981,
      "grad_norm": 2.7455973625183105,
      "learning_rate": 2.4372281449893393e-05,
      "loss": 1.1313,
      "step": 4400
    },
    {
      "epoch": 1.8765195137555981,
      "eval_loss": 1.0066534280776978,
      "eval_runtime": 2.1276,
      "eval_samples_per_second": 464.376,
      "eval_steps_per_second": 58.282,
      "step": 4400
    },
    {
      "epoch": 1.8978460226060994,
      "grad_norm": 2.343808174133301,
      "learning_rate": 2.4308315565031983e-05,
      "loss": 1.0867,
      "step": 4450
    },
    {
      "epoch": 1.9191725314566006,
      "grad_norm": 2.681044578552246,
      "learning_rate": 2.424434968017058e-05,
      "loss": 1.0932,
      "step": 4500
    },
    {
      "epoch": 1.9404990403071016,
      "grad_norm": 4.52717924118042,
      "learning_rate": 2.4180383795309168e-05,
      "loss": 1.1538,
      "step": 4550
    },
    {
      "epoch": 1.9618255491576029,
      "grad_norm": 2.436617851257324,
      "learning_rate": 2.4116417910447764e-05,
      "loss": 1.0384,
      "step": 4600
    },
    {
      "epoch": 1.9618255491576029,
      "eval_loss": 1.0131908655166626,
      "eval_runtime": 2.1549,
      "eval_samples_per_second": 458.486,
      "eval_steps_per_second": 57.543,
      "step": 4600
    },
    {
      "epoch": 1.9831520580081041,
      "grad_norm": 2.670715570449829,
      "learning_rate": 2.4052452025586354e-05,
      "loss": 1.1471,
      "step": 4650
    },
    {
      "epoch": 2.0042653017701,
      "grad_norm": 3.725722074508667,
      "learning_rate": 2.398848614072495e-05,
      "loss": 1.044,
      "step": 4700
    },
    {
      "epoch": 2.0255918106206012,
      "grad_norm": 2.69954252243042,
      "learning_rate": 2.392452025586354e-05,
      "loss": 1.0294,
      "step": 4750
    },
    {
      "epoch": 2.0469183194711027,
      "grad_norm": 2.968863010406494,
      "learning_rate": 2.3860554371002132e-05,
      "loss": 0.9303,
      "step": 4800
    },
    {
      "epoch": 2.0469183194711027,
      "eval_loss": 1.012971043586731,
      "eval_runtime": 2.1401,
      "eval_samples_per_second": 461.665,
      "eval_steps_per_second": 57.942,
      "step": 4800
    },
    {
      "epoch": 2.0682448283216037,
      "grad_norm": 2.1737728118896484,
      "learning_rate": 2.3796588486140725e-05,
      "loss": 1.0471,
      "step": 4850
    },
    {
      "epoch": 2.0895713371721047,
      "grad_norm": 2.454115867614746,
      "learning_rate": 2.3732622601279318e-05,
      "loss": 0.956,
      "step": 4900
    },
    {
      "epoch": 2.110897846022606,
      "grad_norm": 2.213881492614746,
      "learning_rate": 2.366865671641791e-05,
      "loss": 1.0141,
      "step": 4950
    },
    {
      "epoch": 2.1322243548731072,
      "grad_norm": 2.7514047622680664,
      "learning_rate": 2.3604690831556504e-05,
      "loss": 1.0122,
      "step": 5000
    },
    {
      "epoch": 2.1322243548731072,
      "eval_loss": 1.0077122449874878,
      "eval_runtime": 2.1148,
      "eval_samples_per_second": 467.187,
      "eval_steps_per_second": 58.635,
      "step": 5000
    },
    {
      "epoch": 2.1535508637236083,
      "grad_norm": 2.3692679405212402,
      "learning_rate": 2.3540724946695097e-05,
      "loss": 0.9862,
      "step": 5050
    },
    {
      "epoch": 2.1748773725741097,
      "grad_norm": 3.266397476196289,
      "learning_rate": 2.347675906183369e-05,
      "loss": 1.1398,
      "step": 5100
    },
    {
      "epoch": 2.1962038814246108,
      "grad_norm": 3.681067705154419,
      "learning_rate": 2.3412793176972282e-05,
      "loss": 1.0625,
      "step": 5150
    },
    {
      "epoch": 2.217530390275112,
      "grad_norm": 3.042113780975342,
      "learning_rate": 2.3348827292110875e-05,
      "loss": 1.1254,
      "step": 5200
    },
    {
      "epoch": 2.217530390275112,
      "eval_loss": 1.0019807815551758,
      "eval_runtime": 2.1375,
      "eval_samples_per_second": 462.225,
      "eval_steps_per_second": 58.012,
      "step": 5200
    },
    {
      "epoch": 2.2388568991256133,
      "grad_norm": 3.251922369003296,
      "learning_rate": 2.3284861407249468e-05,
      "loss": 0.9735,
      "step": 5250
    },
    {
      "epoch": 2.2601834079761143,
      "grad_norm": 2.8459174633026123,
      "learning_rate": 2.322089552238806e-05,
      "loss": 1.1352,
      "step": 5300
    },
    {
      "epoch": 2.2815099168266153,
      "grad_norm": 2.2224085330963135,
      "learning_rate": 2.3156929637526654e-05,
      "loss": 1.0088,
      "step": 5350
    },
    {
      "epoch": 2.3028364256771168,
      "grad_norm": 2.677006721496582,
      "learning_rate": 2.3092963752665243e-05,
      "loss": 1.0892,
      "step": 5400
    },
    {
      "epoch": 2.3028364256771168,
      "eval_loss": 1.0083104372024536,
      "eval_runtime": 2.1245,
      "eval_samples_per_second": 465.042,
      "eval_steps_per_second": 58.366,
      "step": 5400
    },
    {
      "epoch": 2.324162934527618,
      "grad_norm": 3.638127088546753,
      "learning_rate": 2.302899786780384e-05,
      "loss": 1.1046,
      "step": 5450
    },
    {
      "epoch": 2.345489443378119,
      "grad_norm": 1.939814805984497,
      "learning_rate": 2.296503198294243e-05,
      "loss": 1.0314,
      "step": 5500
    },
    {
      "epoch": 2.3668159522286203,
      "grad_norm": 2.708050012588501,
      "learning_rate": 2.2901066098081025e-05,
      "loss": 0.972,
      "step": 5550
    },
    {
      "epoch": 2.3881424610791213,
      "grad_norm": 2.3387062549591064,
      "learning_rate": 2.2837100213219615e-05,
      "loss": 1.0791,
      "step": 5600
    },
    {
      "epoch": 2.3881424610791213,
      "eval_loss": 0.9944409728050232,
      "eval_runtime": 2.1225,
      "eval_samples_per_second": 465.481,
      "eval_steps_per_second": 58.421,
      "step": 5600
    },
    {
      "epoch": 2.4094689699296223,
      "grad_norm": 2.6323211193084717,
      "learning_rate": 2.277313432835821e-05,
      "loss": 1.0049,
      "step": 5650
    },
    {
      "epoch": 2.430795478780124,
      "grad_norm": 2.001007556915283,
      "learning_rate": 2.27091684434968e-05,
      "loss": 0.9939,
      "step": 5700
    },
    {
      "epoch": 2.452121987630625,
      "grad_norm": 3.617795705795288,
      "learning_rate": 2.2645202558635396e-05,
      "loss": 1.0731,
      "step": 5750
    },
    {
      "epoch": 2.473448496481126,
      "grad_norm": 3.285236120223999,
      "learning_rate": 2.2581236673773986e-05,
      "loss": 1.005,
      "step": 5800
    },
    {
      "epoch": 2.473448496481126,
      "eval_loss": 1.0025032758712769,
      "eval_runtime": 2.1297,
      "eval_samples_per_second": 463.922,
      "eval_steps_per_second": 58.225,
      "step": 5800
    },
    {
      "epoch": 2.4947750053316273,
      "grad_norm": 3.557502508163452,
      "learning_rate": 2.2517270788912582e-05,
      "loss": 1.0717,
      "step": 5850
    },
    {
      "epoch": 2.5161015141821284,
      "grad_norm": 4.333250522613525,
      "learning_rate": 2.245330490405117e-05,
      "loss": 1.0283,
      "step": 5900
    },
    {
      "epoch": 2.5374280230326294,
      "grad_norm": 3.8212904930114746,
      "learning_rate": 2.2389339019189768e-05,
      "loss": 1.0142,
      "step": 5950
    },
    {
      "epoch": 2.558754531883131,
      "grad_norm": 2.4687108993530273,
      "learning_rate": 2.2325373134328357e-05,
      "loss": 1.0411,
      "step": 6000
    },
    {
      "epoch": 2.558754531883131,
      "eval_loss": 1.00029456615448,
      "eval_runtime": 2.1256,
      "eval_samples_per_second": 464.806,
      "eval_steps_per_second": 58.336,
      "step": 6000
    },
    {
      "epoch": 2.580081040733632,
      "grad_norm": 2.72137451171875,
      "learning_rate": 2.2261407249466954e-05,
      "loss": 1.028,
      "step": 6050
    },
    {
      "epoch": 2.601407549584133,
      "grad_norm": 2.767826795578003,
      "learning_rate": 2.2197441364605543e-05,
      "loss": 1.0582,
      "step": 6100
    },
    {
      "epoch": 2.6227340584346344,
      "grad_norm": 3.344397783279419,
      "learning_rate": 2.213347547974414e-05,
      "loss": 1.0677,
      "step": 6150
    },
    {
      "epoch": 2.6440605672851354,
      "grad_norm": 2.4455292224884033,
      "learning_rate": 2.206950959488273e-05,
      "loss": 0.9453,
      "step": 6200
    },
    {
      "epoch": 2.6440605672851354,
      "eval_loss": 1.0001730918884277,
      "eval_runtime": 2.1337,
      "eval_samples_per_second": 463.054,
      "eval_steps_per_second": 58.116,
      "step": 6200
    },
    {
      "epoch": 2.6653870761356364,
      "grad_norm": 3.5410614013671875,
      "learning_rate": 2.2005543710021325e-05,
      "loss": 1.1158,
      "step": 6250
    },
    {
      "epoch": 2.686713584986138,
      "grad_norm": 2.3518078327178955,
      "learning_rate": 2.1941577825159914e-05,
      "loss": 1.0615,
      "step": 6300
    },
    {
      "epoch": 2.708040093836639,
      "grad_norm": 2.7047579288482666,
      "learning_rate": 2.1877611940298507e-05,
      "loss": 1.0243,
      "step": 6350
    },
    {
      "epoch": 2.72936660268714,
      "grad_norm": 2.0227088928222656,
      "learning_rate": 2.18136460554371e-05,
      "loss": 1.0241,
      "step": 6400
    },
    {
      "epoch": 2.72936660268714,
      "eval_loss": 0.9869791269302368,
      "eval_runtime": 2.149,
      "eval_samples_per_second": 459.745,
      "eval_steps_per_second": 57.701,
      "step": 6400
    },
    {
      "epoch": 2.7506931115376414,
      "grad_norm": 3.5233330726623535,
      "learning_rate": 2.1749680170575693e-05,
      "loss": 1.0759,
      "step": 6450
    },
    {
      "epoch": 2.7720196203881424,
      "grad_norm": 2.6458988189697266,
      "learning_rate": 2.1685714285714286e-05,
      "loss": 0.9797,
      "step": 6500
    },
    {
      "epoch": 2.7933461292386434,
      "grad_norm": 3.5767383575439453,
      "learning_rate": 2.162174840085288e-05,
      "loss": 1.0839,
      "step": 6550
    },
    {
      "epoch": 2.814672638089145,
      "grad_norm": 2.968703269958496,
      "learning_rate": 2.155778251599147e-05,
      "loss": 1.1175,
      "step": 6600
    },
    {
      "epoch": 2.814672638089145,
      "eval_loss": 0.9842856526374817,
      "eval_runtime": 2.163,
      "eval_samples_per_second": 456.781,
      "eval_steps_per_second": 57.329,
      "step": 6600
    },
    {
      "epoch": 2.835999146939646,
      "grad_norm": 2.284507989883423,
      "learning_rate": 2.1493816631130064e-05,
      "loss": 1.004,
      "step": 6650
    },
    {
      "epoch": 2.857325655790147,
      "grad_norm": 3.2114269733428955,
      "learning_rate": 2.1429850746268657e-05,
      "loss": 1.1025,
      "step": 6700
    },
    {
      "epoch": 2.8786521646406484,
      "grad_norm": 2.4253859519958496,
      "learning_rate": 2.136588486140725e-05,
      "loss": 1.0397,
      "step": 6750
    },
    {
      "epoch": 2.8999786734911495,
      "grad_norm": 2.2066729068756104,
      "learning_rate": 2.1301918976545843e-05,
      "loss": 1.0212,
      "step": 6800
    },
    {
      "epoch": 2.8999786734911495,
      "eval_loss": 0.989304780960083,
      "eval_runtime": 2.1467,
      "eval_samples_per_second": 460.238,
      "eval_steps_per_second": 57.763,
      "step": 6800
    },
    {
      "epoch": 2.9213051823416505,
      "grad_norm": 3.5448060035705566,
      "learning_rate": 2.1237953091684436e-05,
      "loss": 1.0975,
      "step": 6850
    },
    {
      "epoch": 2.942631691192152,
      "grad_norm": 2.6074085235595703,
      "learning_rate": 2.117398720682303e-05,
      "loss": 1.0143,
      "step": 6900
    },
    {
      "epoch": 2.963958200042653,
      "grad_norm": 2.966862201690674,
      "learning_rate": 2.111002132196162e-05,
      "loss": 1.0191,
      "step": 6950
    },
    {
      "epoch": 2.985284708893154,
      "grad_norm": 2.75893235206604,
      "learning_rate": 2.1046055437100214e-05,
      "loss": 1.1723,
      "step": 7000
    },
    {
      "epoch": 2.985284708893154,
      "eval_loss": 0.9842047691345215,
      "eval_runtime": 2.1173,
      "eval_samples_per_second": 466.632,
      "eval_steps_per_second": 58.565,
      "step": 7000
    },
    {
      "epoch": 3.0063979526551505,
      "grad_norm": 2.408453941345215,
      "learning_rate": 2.0982089552238807e-05,
      "loss": 1.0555,
      "step": 7050
    },
    {
      "epoch": 3.0277244615056516,
      "grad_norm": 3.0720396041870117,
      "learning_rate": 2.09181236673774e-05,
      "loss": 1.089,
      "step": 7100
    },
    {
      "epoch": 3.0490509703561526,
      "grad_norm": 2.2791993618011475,
      "learning_rate": 2.0854157782515993e-05,
      "loss": 0.9593,
      "step": 7150
    },
    {
      "epoch": 3.070377479206654,
      "grad_norm": 2.085707426071167,
      "learning_rate": 2.0790191897654586e-05,
      "loss": 1.0036,
      "step": 7200
    },
    {
      "epoch": 3.070377479206654,
      "eval_loss": 0.987887978553772,
      "eval_runtime": 2.1331,
      "eval_samples_per_second": 463.181,
      "eval_steps_per_second": 58.132,
      "step": 7200
    },
    {
      "epoch": 3.091703988057155,
      "grad_norm": 2.8560190200805664,
      "learning_rate": 2.072622601279318e-05,
      "loss": 1.0717,
      "step": 7250
    },
    {
      "epoch": 3.113030496907656,
      "grad_norm": 2.9553282260894775,
      "learning_rate": 2.066226012793177e-05,
      "loss": 1.0545,
      "step": 7300
    },
    {
      "epoch": 3.1343570057581576,
      "grad_norm": 1.8625068664550781,
      "learning_rate": 2.0598294243070364e-05,
      "loss": 1.0062,
      "step": 7350
    },
    {
      "epoch": 3.1556835146086586,
      "grad_norm": 4.477376937866211,
      "learning_rate": 2.0534328358208957e-05,
      "loss": 1.02,
      "step": 7400
    },
    {
      "epoch": 3.1556835146086586,
      "eval_loss": 0.9916921854019165,
      "eval_runtime": 2.1263,
      "eval_samples_per_second": 464.649,
      "eval_steps_per_second": 58.316,
      "step": 7400
    },
    {
      "epoch": 3.1770100234591596,
      "grad_norm": 3.354090929031372,
      "learning_rate": 2.047036247334755e-05,
      "loss": 0.9458,
      "step": 7450
    },
    {
      "epoch": 3.198336532309661,
      "grad_norm": 1.9965437650680542,
      "learning_rate": 2.0406396588486143e-05,
      "loss": 0.9475,
      "step": 7500
    },
    {
      "epoch": 3.219663041160162,
      "grad_norm": 2.314736843109131,
      "learning_rate": 2.0342430703624732e-05,
      "loss": 1.0269,
      "step": 7550
    },
    {
      "epoch": 3.240989550010663,
      "grad_norm": 2.281548023223877,
      "learning_rate": 2.0278464818763328e-05,
      "loss": 1.0502,
      "step": 7600
    },
    {
      "epoch": 3.240989550010663,
      "eval_loss": 0.9855451583862305,
      "eval_runtime": 2.1365,
      "eval_samples_per_second": 462.432,
      "eval_steps_per_second": 58.038,
      "step": 7600
    },
    {
      "epoch": 3.2623160588611646,
      "grad_norm": 2.805934190750122,
      "learning_rate": 2.0214498933901918e-05,
      "loss": 1.0906,
      "step": 7650
    },
    {
      "epoch": 3.2836425677116656,
      "grad_norm": 2.6569740772247314,
      "learning_rate": 2.0150533049040514e-05,
      "loss": 1.036,
      "step": 7700
    },
    {
      "epoch": 3.3049690765621667,
      "grad_norm": 4.316701889038086,
      "learning_rate": 2.0086567164179103e-05,
      "loss": 1.0176,
      "step": 7750
    },
    {
      "epoch": 3.326295585412668,
      "grad_norm": 2.5392065048217773,
      "learning_rate": 2.00226012793177e-05,
      "loss": 0.9918,
      "step": 7800
    },
    {
      "epoch": 3.326295585412668,
      "eval_loss": 0.9814102053642273,
      "eval_runtime": 2.1302,
      "eval_samples_per_second": 463.812,
      "eval_steps_per_second": 58.211,
      "step": 7800
    },
    {
      "epoch": 3.347622094263169,
      "grad_norm": 2.748220205307007,
      "learning_rate": 1.995863539445629e-05,
      "loss": 1.0746,
      "step": 7850
    },
    {
      "epoch": 3.36894860311367,
      "grad_norm": 3.429550886154175,
      "learning_rate": 1.9894669509594882e-05,
      "loss": 1.0134,
      "step": 7900
    },
    {
      "epoch": 3.3902751119641716,
      "grad_norm": 3.1486802101135254,
      "learning_rate": 1.9830703624733475e-05,
      "loss": 1.0746,
      "step": 7950
    },
    {
      "epoch": 3.4116016208146727,
      "grad_norm": 1.8580023050308228,
      "learning_rate": 1.9766737739872068e-05,
      "loss": 1.0208,
      "step": 8000
    },
    {
      "epoch": 3.4116016208146727,
      "eval_loss": 0.985010027885437,
      "eval_runtime": 2.1622,
      "eval_samples_per_second": 456.95,
      "eval_steps_per_second": 57.35,
      "step": 8000
    },
    {
      "epoch": 3.4329281296651737,
      "grad_norm": 3.139065980911255,
      "learning_rate": 1.970277185501066e-05,
      "loss": 1.0335,
      "step": 8050
    },
    {
      "epoch": 3.454254638515675,
      "grad_norm": 3.3909499645233154,
      "learning_rate": 1.9638805970149253e-05,
      "loss": 0.9179,
      "step": 8100
    },
    {
      "epoch": 3.475581147366176,
      "grad_norm": 2.6308248043060303,
      "learning_rate": 1.9574840085287846e-05,
      "loss": 1.0262,
      "step": 8150
    },
    {
      "epoch": 3.496907656216677,
      "grad_norm": 1.6000241041183472,
      "learning_rate": 1.951087420042644e-05,
      "loss": 1.0126,
      "step": 8200
    },
    {
      "epoch": 3.496907656216677,
      "eval_loss": 0.9828559160232544,
      "eval_runtime": 2.1185,
      "eval_samples_per_second": 466.364,
      "eval_steps_per_second": 58.532,
      "step": 8200
    },
    {
      "epoch": 3.5182341650671782,
      "grad_norm": 2.371068000793457,
      "learning_rate": 1.9446908315565032e-05,
      "loss": 0.9365,
      "step": 8250
    },
    {
      "epoch": 3.5395606739176797,
      "grad_norm": 2.9577863216400146,
      "learning_rate": 1.9382942430703625e-05,
      "loss": 0.9746,
      "step": 8300
    },
    {
      "epoch": 3.5608871827681807,
      "grad_norm": 2.249899387359619,
      "learning_rate": 1.9318976545842218e-05,
      "loss": 1.0116,
      "step": 8350
    },
    {
      "epoch": 3.5822136916186818,
      "grad_norm": 2.495344877243042,
      "learning_rate": 1.925501066098081e-05,
      "loss": 0.9338,
      "step": 8400
    },
    {
      "epoch": 3.5822136916186818,
      "eval_loss": 0.9843441247940063,
      "eval_runtime": 2.1333,
      "eval_samples_per_second": 463.141,
      "eval_steps_per_second": 58.127,
      "step": 8400
    },
    {
      "epoch": 3.603540200469183,
      "grad_norm": 2.224942445755005,
      "learning_rate": 1.9191044776119403e-05,
      "loss": 1.051,
      "step": 8450
    },
    {
      "epoch": 3.6248667093196842,
      "grad_norm": 3.687739372253418,
      "learning_rate": 1.9127078891257996e-05,
      "loss": 1.0038,
      "step": 8500
    },
    {
      "epoch": 3.6461932181701853,
      "grad_norm": 3.2388999462127686,
      "learning_rate": 1.906311300639659e-05,
      "loss": 1.0017,
      "step": 8550
    },
    {
      "epoch": 3.6675197270206867,
      "grad_norm": 2.6716418266296387,
      "learning_rate": 1.8999147121535182e-05,
      "loss": 0.9689,
      "step": 8600
    },
    {
      "epoch": 3.6675197270206867,
      "eval_loss": 0.9892188906669617,
      "eval_runtime": 2.1332,
      "eval_samples_per_second": 463.15,
      "eval_steps_per_second": 58.128,
      "step": 8600
    },
    {
      "epoch": 3.6888462358711878,
      "grad_norm": 3.183363914489746,
      "learning_rate": 1.8935181236673775e-05,
      "loss": 1.0188,
      "step": 8650
    },
    {
      "epoch": 3.710172744721689,
      "grad_norm": 2.925381898880005,
      "learning_rate": 1.8871215351812367e-05,
      "loss": 0.9687,
      "step": 8700
    },
    {
      "epoch": 3.7314992535721903,
      "grad_norm": 2.6509416103363037,
      "learning_rate": 1.880724946695096e-05,
      "loss": 1.0251,
      "step": 8750
    },
    {
      "epoch": 3.7528257624226913,
      "grad_norm": 3.775414228439331,
      "learning_rate": 1.8743283582089553e-05,
      "loss": 1.0755,
      "step": 8800
    },
    {
      "epoch": 3.7528257624226913,
      "eval_loss": 0.9790681600570679,
      "eval_runtime": 2.1595,
      "eval_samples_per_second": 457.506,
      "eval_steps_per_second": 57.42,
      "step": 8800
    },
    {
      "epoch": 3.7741522712731923,
      "grad_norm": 2.911421298980713,
      "learning_rate": 1.8679317697228146e-05,
      "loss": 0.9448,
      "step": 8850
    },
    {
      "epoch": 3.7954787801236938,
      "grad_norm": 3.7687127590179443,
      "learning_rate": 1.861535181236674e-05,
      "loss": 1.0942,
      "step": 8900
    },
    {
      "epoch": 3.816805288974195,
      "grad_norm": 2.1260435581207275,
      "learning_rate": 1.855138592750533e-05,
      "loss": 1.0136,
      "step": 8950
    },
    {
      "epoch": 3.838131797824696,
      "grad_norm": 2.502782106399536,
      "learning_rate": 1.8487420042643924e-05,
      "loss": 0.9377,
      "step": 9000
    },
    {
      "epoch": 3.838131797824696,
      "eval_loss": 0.9789151549339294,
      "eval_runtime": 2.1291,
      "eval_samples_per_second": 464.038,
      "eval_steps_per_second": 58.24,
      "step": 9000
    },
    {
      "epoch": 3.8594583066751973,
      "grad_norm": 2.5836069583892822,
      "learning_rate": 1.8423454157782517e-05,
      "loss": 1.0291,
      "step": 9050
    },
    {
      "epoch": 3.8807848155256983,
      "grad_norm": 2.194558620452881,
      "learning_rate": 1.835948827292111e-05,
      "loss": 0.9574,
      "step": 9100
    },
    {
      "epoch": 3.9021113243761993,
      "grad_norm": 1.9195271730422974,
      "learning_rate": 1.8295522388059703e-05,
      "loss": 1.0627,
      "step": 9150
    },
    {
      "epoch": 3.923437833226701,
      "grad_norm": 5.127684116363525,
      "learning_rate": 1.8231556503198296e-05,
      "loss": 1.0526,
      "step": 9200
    },
    {
      "epoch": 3.923437833226701,
      "eval_loss": 0.9743223786354065,
      "eval_runtime": 2.1414,
      "eval_samples_per_second": 461.387,
      "eval_steps_per_second": 57.907,
      "step": 9200
    },
    {
      "epoch": 3.944764342077202,
      "grad_norm": 3.6377134323120117,
      "learning_rate": 1.816759061833689e-05,
      "loss": 0.9354,
      "step": 9250
    },
    {
      "epoch": 3.966090850927703,
      "grad_norm": 2.1689887046813965,
      "learning_rate": 1.810362473347548e-05,
      "loss": 1.0612,
      "step": 9300
    },
    {
      "epoch": 3.9874173597782043,
      "grad_norm": 2.827883720397949,
      "learning_rate": 1.8039658848614074e-05,
      "loss": 0.9499,
      "step": 9350
    },
    {
      "epoch": 4.0085306035402,
      "grad_norm": 2.3187620639801025,
      "learning_rate": 1.7975692963752667e-05,
      "loss": 1.0583,
      "step": 9400
    },
    {
      "epoch": 4.0085306035402,
      "eval_loss": 0.9735326170921326,
      "eval_runtime": 2.128,
      "eval_samples_per_second": 464.279,
      "eval_steps_per_second": 58.27,
      "step": 9400
    },
    {
      "epoch": 4.029857112390702,
      "grad_norm": 2.9459688663482666,
      "learning_rate": 1.7911727078891257e-05,
      "loss": 0.9617,
      "step": 9450
    },
    {
      "epoch": 4.0511836212412025,
      "grad_norm": 4.103748321533203,
      "learning_rate": 1.7847761194029853e-05,
      "loss": 1.0201,
      "step": 9500
    },
    {
      "epoch": 4.072510130091704,
      "grad_norm": 2.517083168029785,
      "learning_rate": 1.7783795309168442e-05,
      "loss": 1.0224,
      "step": 9550
    },
    {
      "epoch": 4.093836638942205,
      "grad_norm": 2.4813120365142822,
      "learning_rate": 1.7719829424307035e-05,
      "loss": 1.0245,
      "step": 9600
    },
    {
      "epoch": 4.093836638942205,
      "eval_loss": 0.9733110070228577,
      "eval_runtime": 2.1493,
      "eval_samples_per_second": 459.69,
      "eval_steps_per_second": 57.694,
      "step": 9600
    },
    {
      "epoch": 4.115163147792706,
      "grad_norm": 2.2447009086608887,
      "learning_rate": 1.7655863539445628e-05,
      "loss": 0.9796,
      "step": 9650
    },
    {
      "epoch": 4.1364896566432074,
      "grad_norm": 2.6685550212860107,
      "learning_rate": 1.759189765458422e-05,
      "loss": 1.0135,
      "step": 9700
    },
    {
      "epoch": 4.157816165493709,
      "grad_norm": 2.4102237224578857,
      "learning_rate": 1.7527931769722814e-05,
      "loss": 0.9797,
      "step": 9750
    },
    {
      "epoch": 4.1791426743442095,
      "grad_norm": 2.7600042819976807,
      "learning_rate": 1.7463965884861407e-05,
      "loss": 1.0358,
      "step": 9800
    },
    {
      "epoch": 4.1791426743442095,
      "eval_loss": 0.9761353135108948,
      "eval_runtime": 2.1336,
      "eval_samples_per_second": 463.06,
      "eval_steps_per_second": 58.117,
      "step": 9800
    },
    {
      "epoch": 4.200469183194711,
      "grad_norm": 2.5570335388183594,
      "learning_rate": 1.74e-05,
      "loss": 0.9798,
      "step": 9850
    },
    {
      "epoch": 4.221795692045212,
      "grad_norm": 2.3455147743225098,
      "learning_rate": 1.7336034115138592e-05,
      "loss": 0.8756,
      "step": 9900
    },
    {
      "epoch": 4.243122200895713,
      "grad_norm": 2.691030740737915,
      "learning_rate": 1.7272068230277185e-05,
      "loss": 0.9681,
      "step": 9950
    },
    {
      "epoch": 4.2644487097462145,
      "grad_norm": 3.068286418914795,
      "learning_rate": 1.7208102345415778e-05,
      "loss": 0.9423,
      "step": 10000
    },
    {
      "epoch": 4.2644487097462145,
      "eval_loss": 0.9782062768936157,
      "eval_runtime": 2.1364,
      "eval_samples_per_second": 462.464,
      "eval_steps_per_second": 58.042,
      "step": 10000
    },
    {
      "epoch": 4.285775218596716,
      "grad_norm": 3.5896363258361816,
      "learning_rate": 1.714413646055437e-05,
      "loss": 0.9564,
      "step": 10050
    },
    {
      "epoch": 4.3071017274472165,
      "grad_norm": 2.66025447845459,
      "learning_rate": 1.7080170575692964e-05,
      "loss": 0.9239,
      "step": 10100
    },
    {
      "epoch": 4.328428236297718,
      "grad_norm": 4.886200904846191,
      "learning_rate": 1.7016204690831556e-05,
      "loss": 0.9456,
      "step": 10150
    },
    {
      "epoch": 4.3497547451482195,
      "grad_norm": 2.672616481781006,
      "learning_rate": 1.695223880597015e-05,
      "loss": 0.8664,
      "step": 10200
    },
    {
      "epoch": 4.3497547451482195,
      "eval_loss": 0.9735167622566223,
      "eval_runtime": 2.1403,
      "eval_samples_per_second": 461.619,
      "eval_steps_per_second": 57.936,
      "step": 10200
    },
    {
      "epoch": 4.37108125399872,
      "grad_norm": 2.807799816131592,
      "learning_rate": 1.6888272921108742e-05,
      "loss": 1.0364,
      "step": 10250
    },
    {
      "epoch": 4.3924077628492215,
      "grad_norm": 2.1114330291748047,
      "learning_rate": 1.6824307036247335e-05,
      "loss": 1.007,
      "step": 10300
    },
    {
      "epoch": 4.413734271699723,
      "grad_norm": 2.5827925205230713,
      "learning_rate": 1.6760341151385928e-05,
      "loss": 0.9662,
      "step": 10350
    },
    {
      "epoch": 4.435060780550224,
      "grad_norm": 2.4621973037719727,
      "learning_rate": 1.669637526652452e-05,
      "loss": 1.0294,
      "step": 10400
    },
    {
      "epoch": 4.435060780550224,
      "eval_loss": 0.9694663882255554,
      "eval_runtime": 2.1312,
      "eval_samples_per_second": 463.579,
      "eval_steps_per_second": 58.182,
      "step": 10400
    },
    {
      "epoch": 4.456387289400725,
      "grad_norm": 2.6306638717651367,
      "learning_rate": 1.6632409381663114e-05,
      "loss": 1.0721,
      "step": 10450
    },
    {
      "epoch": 4.4777137982512265,
      "grad_norm": 2.6001574993133545,
      "learning_rate": 1.6568443496801706e-05,
      "loss": 0.9331,
      "step": 10500
    },
    {
      "epoch": 4.499040307101727,
      "grad_norm": 2.760863780975342,
      "learning_rate": 1.65044776119403e-05,
      "loss": 0.9418,
      "step": 10550
    },
    {
      "epoch": 4.520366815952229,
      "grad_norm": 1.929939866065979,
      "learning_rate": 1.6440511727078892e-05,
      "loss": 1.0343,
      "step": 10600
    },
    {
      "epoch": 4.520366815952229,
      "eval_loss": 0.9708195924758911,
      "eval_runtime": 2.1319,
      "eval_samples_per_second": 463.446,
      "eval_steps_per_second": 58.165,
      "step": 10600
    },
    {
      "epoch": 4.54169332480273,
      "grad_norm": 2.408581018447876,
      "learning_rate": 1.6376545842217485e-05,
      "loss": 0.9769,
      "step": 10650
    },
    {
      "epoch": 4.563019833653231,
      "grad_norm": 2.2852795124053955,
      "learning_rate": 1.6312579957356078e-05,
      "loss": 1.0409,
      "step": 10700
    },
    {
      "epoch": 4.584346342503732,
      "grad_norm": 1.1703970432281494,
      "learning_rate": 1.624861407249467e-05,
      "loss": 1.0093,
      "step": 10750
    },
    {
      "epoch": 4.6056728513542335,
      "grad_norm": 2.233369827270508,
      "learning_rate": 1.6184648187633263e-05,
      "loss": 1.0039,
      "step": 10800
    },
    {
      "epoch": 4.6056728513542335,
      "eval_loss": 0.9767072200775146,
      "eval_runtime": 2.1463,
      "eval_samples_per_second": 460.317,
      "eval_steps_per_second": 57.773,
      "step": 10800
    },
    {
      "epoch": 4.626999360204734,
      "grad_norm": 2.1255428791046143,
      "learning_rate": 1.6120682302771856e-05,
      "loss": 0.988,
      "step": 10850
    },
    {
      "epoch": 4.648325869055236,
      "grad_norm": 2.7627320289611816,
      "learning_rate": 1.605671641791045e-05,
      "loss": 1.0307,
      "step": 10900
    },
    {
      "epoch": 4.669652377905737,
      "grad_norm": 2.9617233276367188,
      "learning_rate": 1.5992750533049042e-05,
      "loss": 0.9923,
      "step": 10950
    },
    {
      "epoch": 4.690978886756238,
      "grad_norm": 2.7485392093658447,
      "learning_rate": 1.592878464818763e-05,
      "loss": 0.9987,
      "step": 11000
    },
    {
      "epoch": 4.690978886756238,
      "eval_loss": 0.9694098830223083,
      "eval_runtime": 2.1327,
      "eval_samples_per_second": 463.257,
      "eval_steps_per_second": 58.142,
      "step": 11000
    },
    {
      "epoch": 4.712305395606739,
      "grad_norm": 1.9472064971923828,
      "learning_rate": 1.5864818763326228e-05,
      "loss": 0.9365,
      "step": 11050
    },
    {
      "epoch": 4.733631904457241,
      "grad_norm": 3.2088286876678467,
      "learning_rate": 1.5800852878464817e-05,
      "loss": 0.9653,
      "step": 11100
    },
    {
      "epoch": 4.754958413307741,
      "grad_norm": 2.688175916671753,
      "learning_rate": 1.5736886993603413e-05,
      "loss": 1.0409,
      "step": 11150
    },
    {
      "epoch": 4.776284922158243,
      "grad_norm": 2.2513952255249023,
      "learning_rate": 1.5672921108742003e-05,
      "loss": 0.8984,
      "step": 11200
    },
    {
      "epoch": 4.776284922158243,
      "eval_loss": 0.9687391519546509,
      "eval_runtime": 2.1454,
      "eval_samples_per_second": 460.527,
      "eval_steps_per_second": 57.799,
      "step": 11200
    },
    {
      "epoch": 4.797611431008744,
      "grad_norm": 3.177860975265503,
      "learning_rate": 1.56089552238806e-05,
      "loss": 0.9223,
      "step": 11250
    },
    {
      "epoch": 4.818937939859245,
      "grad_norm": 2.201641082763672,
      "learning_rate": 1.554498933901919e-05,
      "loss": 0.9783,
      "step": 11300
    },
    {
      "epoch": 4.840264448709746,
      "grad_norm": 2.9840688705444336,
      "learning_rate": 1.5481023454157785e-05,
      "loss": 1.0766,
      "step": 11350
    },
    {
      "epoch": 4.861590957560248,
      "grad_norm": 3.8879635334014893,
      "learning_rate": 1.5417057569296374e-05,
      "loss": 0.9309,
      "step": 11400
    },
    {
      "epoch": 4.861590957560248,
      "eval_loss": 0.9699276089668274,
      "eval_runtime": 2.1279,
      "eval_samples_per_second": 464.307,
      "eval_steps_per_second": 58.273,
      "step": 11400
    },
    {
      "epoch": 4.882917466410748,
      "grad_norm": 2.3718090057373047,
      "learning_rate": 1.535309168443497e-05,
      "loss": 0.9642,
      "step": 11450
    },
    {
      "epoch": 4.90424397526125,
      "grad_norm": 2.446507453918457,
      "learning_rate": 1.528912579957356e-05,
      "loss": 0.9076,
      "step": 11500
    },
    {
      "epoch": 4.925570484111751,
      "grad_norm": 3.245168685913086,
      "learning_rate": 1.5225159914712154e-05,
      "loss": 0.9277,
      "step": 11550
    },
    {
      "epoch": 4.946896992962252,
      "grad_norm": 3.671668291091919,
      "learning_rate": 1.5161194029850746e-05,
      "loss": 1.031,
      "step": 11600
    },
    {
      "epoch": 4.946896992962252,
      "eval_loss": 0.9696972370147705,
      "eval_runtime": 2.1362,
      "eval_samples_per_second": 462.514,
      "eval_steps_per_second": 58.048,
      "step": 11600
    },
    {
      "epoch": 4.968223501812753,
      "grad_norm": 2.9612677097320557,
      "learning_rate": 1.509722814498934e-05,
      "loss": 0.9904,
      "step": 11650
    },
    {
      "epoch": 4.989550010663255,
      "grad_norm": 2.911097526550293,
      "learning_rate": 1.5033262260127931e-05,
      "loss": 1.0048,
      "step": 11700
    },
    {
      "epoch": 5.010663254425251,
      "grad_norm": 3.766833543777466,
      "learning_rate": 1.4969296375266526e-05,
      "loss": 0.9762,
      "step": 11750
    },
    {
      "epoch": 5.031989763275751,
      "grad_norm": 2.788078546524048,
      "learning_rate": 1.4905330490405117e-05,
      "loss": 0.927,
      "step": 11800
    },
    {
      "epoch": 5.031989763275751,
      "eval_loss": 0.9721306562423706,
      "eval_runtime": 2.141,
      "eval_samples_per_second": 461.461,
      "eval_steps_per_second": 57.916,
      "step": 11800
    },
    {
      "epoch": 5.053316272126253,
      "grad_norm": 2.156376600265503,
      "learning_rate": 1.484136460554371e-05,
      "loss": 0.9621,
      "step": 11850
    },
    {
      "epoch": 5.074642780976754,
      "grad_norm": 2.172501564025879,
      "learning_rate": 1.4777398720682303e-05,
      "loss": 0.9145,
      "step": 11900
    },
    {
      "epoch": 5.095969289827256,
      "grad_norm": 2.460361957550049,
      "learning_rate": 1.4713432835820895e-05,
      "loss": 0.9421,
      "step": 11950
    },
    {
      "epoch": 5.117295798677756,
      "grad_norm": 2.599987268447876,
      "learning_rate": 1.4649466950959488e-05,
      "loss": 1.053,
      "step": 12000
    },
    {
      "epoch": 5.117295798677756,
      "eval_loss": 0.9682052135467529,
      "eval_runtime": 2.134,
      "eval_samples_per_second": 462.974,
      "eval_steps_per_second": 58.106,
      "step": 12000
    },
    {
      "epoch": 5.138622307528258,
      "grad_norm": 1.7657015323638916,
      "learning_rate": 1.4585501066098081e-05,
      "loss": 0.9194,
      "step": 12050
    },
    {
      "epoch": 5.159948816378758,
      "grad_norm": 2.19128155708313,
      "learning_rate": 1.4521535181236674e-05,
      "loss": 0.9491,
      "step": 12100
    },
    {
      "epoch": 5.18127532522926,
      "grad_norm": 1.8909761905670166,
      "learning_rate": 1.4457569296375267e-05,
      "loss": 0.9745,
      "step": 12150
    },
    {
      "epoch": 5.202601834079761,
      "grad_norm": 2.2263126373291016,
      "learning_rate": 1.439360341151386e-05,
      "loss": 0.9893,
      "step": 12200
    },
    {
      "epoch": 5.202601834079761,
      "eval_loss": 0.9714611172676086,
      "eval_runtime": 2.1302,
      "eval_samples_per_second": 463.809,
      "eval_steps_per_second": 58.211,
      "step": 12200
    },
    {
      "epoch": 5.223928342930263,
      "grad_norm": 2.705650568008423,
      "learning_rate": 1.4329637526652452e-05,
      "loss": 1.0001,
      "step": 12250
    },
    {
      "epoch": 5.245254851780763,
      "grad_norm": 2.5968666076660156,
      "learning_rate": 1.4265671641791045e-05,
      "loss": 0.991,
      "step": 12300
    },
    {
      "epoch": 5.266581360631265,
      "grad_norm": 4.19283390045166,
      "learning_rate": 1.4201705756929638e-05,
      "loss": 0.9782,
      "step": 12350
    },
    {
      "epoch": 5.287907869481765,
      "grad_norm": 2.8895909786224365,
      "learning_rate": 1.4137739872068231e-05,
      "loss": 0.9916,
      "step": 12400
    },
    {
      "epoch": 5.287907869481765,
      "eval_loss": 0.9725934863090515,
      "eval_runtime": 2.1375,
      "eval_samples_per_second": 462.223,
      "eval_steps_per_second": 58.012,
      "step": 12400
    },
    {
      "epoch": 5.309234378332267,
      "grad_norm": 2.8876118659973145,
      "learning_rate": 1.4073773987206824e-05,
      "loss": 1.0284,
      "step": 12450
    },
    {
      "epoch": 5.330560887182768,
      "grad_norm": 5.503377914428711,
      "learning_rate": 1.4009808102345417e-05,
      "loss": 1.0147,
      "step": 12500
    },
    {
      "epoch": 5.35188739603327,
      "grad_norm": 1.9752248525619507,
      "learning_rate": 1.394584221748401e-05,
      "loss": 0.9283,
      "step": 12550
    },
    {
      "epoch": 5.37321390488377,
      "grad_norm": 2.7002272605895996,
      "learning_rate": 1.3881876332622602e-05,
      "loss": 1.0077,
      "step": 12600
    },
    {
      "epoch": 5.37321390488377,
      "eval_loss": 0.9664686322212219,
      "eval_runtime": 2.1305,
      "eval_samples_per_second": 463.746,
      "eval_steps_per_second": 58.203,
      "step": 12600
    },
    {
      "epoch": 5.394540413734272,
      "grad_norm": 2.7525575160980225,
      "learning_rate": 1.3817910447761195e-05,
      "loss": 0.9192,
      "step": 12650
    },
    {
      "epoch": 5.415866922584772,
      "grad_norm": 3.4731099605560303,
      "learning_rate": 1.3753944562899788e-05,
      "loss": 0.9945,
      "step": 12700
    },
    {
      "epoch": 5.437193431435274,
      "grad_norm": 2.4396471977233887,
      "learning_rate": 1.3689978678038381e-05,
      "loss": 0.9861,
      "step": 12750
    },
    {
      "epoch": 5.458519940285775,
      "grad_norm": 3.319753408432007,
      "learning_rate": 1.3626012793176972e-05,
      "loss": 0.9289,
      "step": 12800
    },
    {
      "epoch": 5.458519940285775,
      "eval_loss": 0.9697991013526917,
      "eval_runtime": 2.1211,
      "eval_samples_per_second": 465.796,
      "eval_steps_per_second": 58.46,
      "step": 12800
    },
    {
      "epoch": 5.479846449136277,
      "grad_norm": 2.571974039077759,
      "learning_rate": 1.3562046908315565e-05,
      "loss": 0.9277,
      "step": 12850
    },
    {
      "epoch": 5.501172957986777,
      "grad_norm": 2.297250747680664,
      "learning_rate": 1.3498081023454158e-05,
      "loss": 0.9828,
      "step": 12900
    },
    {
      "epoch": 5.522499466837279,
      "grad_norm": 3.0683395862579346,
      "learning_rate": 1.343411513859275e-05,
      "loss": 0.9204,
      "step": 12950
    },
    {
      "epoch": 5.5438259756877795,
      "grad_norm": 2.6813387870788574,
      "learning_rate": 1.3370149253731343e-05,
      "loss": 1.0089,
      "step": 13000
    },
    {
      "epoch": 5.5438259756877795,
      "eval_loss": 0.9653539061546326,
      "eval_runtime": 2.1379,
      "eval_samples_per_second": 462.146,
      "eval_steps_per_second": 58.002,
      "step": 13000
    },
    {
      "epoch": 5.565152484538281,
      "grad_norm": 1.9787145853042603,
      "learning_rate": 1.3306183368869936e-05,
      "loss": 0.9116,
      "step": 13050
    },
    {
      "epoch": 5.586478993388782,
      "grad_norm": 1.9243603944778442,
      "learning_rate": 1.3242217484008529e-05,
      "loss": 0.9183,
      "step": 13100
    },
    {
      "epoch": 5.607805502239284,
      "grad_norm": 3.063551664352417,
      "learning_rate": 1.3178251599147122e-05,
      "loss": 0.9506,
      "step": 13150
    },
    {
      "epoch": 5.6291320110897844,
      "grad_norm": 5.014166355133057,
      "learning_rate": 1.3114285714285715e-05,
      "loss": 0.9076,
      "step": 13200
    },
    {
      "epoch": 5.6291320110897844,
      "eval_loss": 0.9649452567100525,
      "eval_runtime": 2.1575,
      "eval_samples_per_second": 457.947,
      "eval_steps_per_second": 57.475,
      "step": 13200
    },
    {
      "epoch": 5.650458519940286,
      "grad_norm": 4.2195725440979,
      "learning_rate": 1.3050319829424308e-05,
      "loss": 0.9888,
      "step": 13250
    },
    {
      "epoch": 5.6717850287907865,
      "grad_norm": 2.4001576900482178,
      "learning_rate": 1.29863539445629e-05,
      "loss": 0.9549,
      "step": 13300
    },
    {
      "epoch": 5.693111537641288,
      "grad_norm": 2.714681625366211,
      "learning_rate": 1.2922388059701492e-05,
      "loss": 0.9064,
      "step": 13350
    },
    {
      "epoch": 5.714438046491789,
      "grad_norm": 2.6150014400482178,
      "learning_rate": 1.2858422174840084e-05,
      "loss": 0.9733,
      "step": 13400
    },
    {
      "epoch": 5.714438046491789,
      "eval_loss": 0.9685788750648499,
      "eval_runtime": 2.141,
      "eval_samples_per_second": 461.476,
      "eval_steps_per_second": 57.918,
      "step": 13400
    },
    {
      "epoch": 5.735764555342291,
      "grad_norm": 2.644458055496216,
      "learning_rate": 1.2794456289978677e-05,
      "loss": 0.9415,
      "step": 13450
    },
    {
      "epoch": 5.7570910641927915,
      "grad_norm": 2.872551202774048,
      "learning_rate": 1.273049040511727e-05,
      "loss": 1.0038,
      "step": 13500
    },
    {
      "epoch": 5.778417573043293,
      "grad_norm": 3.2170913219451904,
      "learning_rate": 1.2666524520255863e-05,
      "loss": 1.0404,
      "step": 13550
    },
    {
      "epoch": 5.7997440818937935,
      "grad_norm": 1.321602702140808,
      "learning_rate": 1.2602558635394456e-05,
      "loss": 0.934,
      "step": 13600
    },
    {
      "epoch": 5.7997440818937935,
      "eval_loss": 0.9685658812522888,
      "eval_runtime": 2.1378,
      "eval_samples_per_second": 462.163,
      "eval_steps_per_second": 58.004,
      "step": 13600
    },
    {
      "epoch": 5.821070590744295,
      "grad_norm": 2.697624444961548,
      "learning_rate": 1.2538592750533049e-05,
      "loss": 1.0326,
      "step": 13650
    },
    {
      "epoch": 5.8423970995947965,
      "grad_norm": 1.5964258909225464,
      "learning_rate": 1.2474626865671642e-05,
      "loss": 0.9421,
      "step": 13700
    },
    {
      "epoch": 5.863723608445298,
      "grad_norm": 2.310286045074463,
      "learning_rate": 1.2410660980810234e-05,
      "loss": 0.9117,
      "step": 13750
    },
    {
      "epoch": 5.8850501172957985,
      "grad_norm": 2.837435245513916,
      "learning_rate": 1.2346695095948827e-05,
      "loss": 0.943,
      "step": 13800
    },
    {
      "epoch": 5.8850501172957985,
      "eval_loss": 0.9652718901634216,
      "eval_runtime": 2.143,
      "eval_samples_per_second": 461.025,
      "eval_steps_per_second": 57.861,
      "step": 13800
    },
    {
      "epoch": 5.9063766261463,
      "grad_norm": 2.702850341796875,
      "learning_rate": 1.228272921108742e-05,
      "loss": 0.9272,
      "step": 13850
    },
    {
      "epoch": 5.927703134996801,
      "grad_norm": 23.913219451904297,
      "learning_rate": 1.2218763326226013e-05,
      "loss": 1.0128,
      "step": 13900
    },
    {
      "epoch": 5.949029643847302,
      "grad_norm": 3.9560189247131348,
      "learning_rate": 1.2154797441364606e-05,
      "loss": 1.0036,
      "step": 13950
    },
    {
      "epoch": 5.9703561526978035,
      "grad_norm": 2.5488288402557373,
      "learning_rate": 1.2090831556503199e-05,
      "loss": 0.93,
      "step": 14000
    },
    {
      "epoch": 5.9703561526978035,
      "eval_loss": 0.968626856803894,
      "eval_runtime": 2.1433,
      "eval_samples_per_second": 460.975,
      "eval_steps_per_second": 57.855,
      "step": 14000
    },
    {
      "epoch": 5.991682661548305,
      "grad_norm": 2.7064900398254395,
      "learning_rate": 1.2026865671641791e-05,
      "loss": 0.982,
      "step": 14050
    },
    {
      "epoch": 6.012795905310301,
      "grad_norm": 3.1206345558166504,
      "learning_rate": 1.1962899786780384e-05,
      "loss": 0.9104,
      "step": 14100
    },
    {
      "epoch": 6.034122414160802,
      "grad_norm": 2.8864307403564453,
      "learning_rate": 1.1898933901918977e-05,
      "loss": 0.8773,
      "step": 14150
    },
    {
      "epoch": 6.055448923011303,
      "grad_norm": 2.6515390872955322,
      "learning_rate": 1.183496801705757e-05,
      "loss": 0.9288,
      "step": 14200
    },
    {
      "epoch": 6.055448923011303,
      "eval_loss": 0.9631224274635315,
      "eval_runtime": 2.1298,
      "eval_samples_per_second": 463.893,
      "eval_steps_per_second": 58.221,
      "step": 14200
    },
    {
      "epoch": 6.076775431861805,
      "grad_norm": 2.753775119781494,
      "learning_rate": 1.1771002132196163e-05,
      "loss": 0.9805,
      "step": 14250
    },
    {
      "epoch": 6.098101940712305,
      "grad_norm": 3.4586453437805176,
      "learning_rate": 1.1707036247334756e-05,
      "loss": 0.932,
      "step": 14300
    },
    {
      "epoch": 6.119428449562807,
      "grad_norm": 2.6670305728912354,
      "learning_rate": 1.1643070362473349e-05,
      "loss": 0.9092,
      "step": 14350
    },
    {
      "epoch": 6.140754958413308,
      "grad_norm": 3.114203929901123,
      "learning_rate": 1.1579104477611941e-05,
      "loss": 0.9645,
      "step": 14400
    },
    {
      "epoch": 6.140754958413308,
      "eval_loss": 0.9650490283966064,
      "eval_runtime": 2.1342,
      "eval_samples_per_second": 462.94,
      "eval_steps_per_second": 58.102,
      "step": 14400
    },
    {
      "epoch": 6.162081467263809,
      "grad_norm": 2.7008156776428223,
      "learning_rate": 1.1515138592750534e-05,
      "loss": 0.988,
      "step": 14450
    },
    {
      "epoch": 6.18340797611431,
      "grad_norm": 3.5579872131347656,
      "learning_rate": 1.1451172707889127e-05,
      "loss": 0.8985,
      "step": 14500
    },
    {
      "epoch": 6.204734484964812,
      "grad_norm": 1.6427470445632935,
      "learning_rate": 1.138720682302772e-05,
      "loss": 0.9904,
      "step": 14550
    },
    {
      "epoch": 6.226060993815312,
      "grad_norm": 3.3309242725372314,
      "learning_rate": 1.1323240938166313e-05,
      "loss": 0.9778,
      "step": 14600
    },
    {
      "epoch": 6.226060993815312,
      "eval_loss": 0.9602293968200684,
      "eval_runtime": 2.132,
      "eval_samples_per_second": 463.422,
      "eval_steps_per_second": 58.162,
      "step": 14600
    },
    {
      "epoch": 6.247387502665814,
      "grad_norm": 3.606968879699707,
      "learning_rate": 1.1259275053304906e-05,
      "loss": 0.9908,
      "step": 14650
    },
    {
      "epoch": 6.268714011516315,
      "grad_norm": 2.3811004161834717,
      "learning_rate": 1.1195309168443498e-05,
      "loss": 1.0193,
      "step": 14700
    },
    {
      "epoch": 6.290040520366816,
      "grad_norm": 2.246882677078247,
      "learning_rate": 1.1131343283582091e-05,
      "loss": 0.8659,
      "step": 14750
    },
    {
      "epoch": 6.311367029217317,
      "grad_norm": 2.4596104621887207,
      "learning_rate": 1.1067377398720684e-05,
      "loss": 0.9431,
      "step": 14800
    },
    {
      "epoch": 6.311367029217317,
      "eval_loss": 0.9649696350097656,
      "eval_runtime": 2.1285,
      "eval_samples_per_second": 464.186,
      "eval_steps_per_second": 58.258,
      "step": 14800
    },
    {
      "epoch": 6.332693538067819,
      "grad_norm": 3.1362826824188232,
      "learning_rate": 1.1003411513859277e-05,
      "loss": 0.9651,
      "step": 14850
    },
    {
      "epoch": 6.354020046918319,
      "grad_norm": 2.5759828090667725,
      "learning_rate": 1.0939445628997868e-05,
      "loss": 0.924,
      "step": 14900
    },
    {
      "epoch": 6.375346555768821,
      "grad_norm": 2.373223066329956,
      "learning_rate": 1.087547974413646e-05,
      "loss": 0.907,
      "step": 14950
    },
    {
      "epoch": 6.396673064619322,
      "grad_norm": 3.094750165939331,
      "learning_rate": 1.0811513859275052e-05,
      "loss": 0.9627,
      "step": 15000
    },
    {
      "epoch": 6.396673064619322,
      "eval_loss": 0.9651111364364624,
      "eval_runtime": 2.1512,
      "eval_samples_per_second": 459.288,
      "eval_steps_per_second": 57.643,
      "step": 15000
    },
    {
      "epoch": 6.417999573469823,
      "grad_norm": 2.5785467624664307,
      "learning_rate": 1.0747547974413645e-05,
      "loss": 0.9449,
      "step": 15050
    },
    {
      "epoch": 6.439326082320324,
      "grad_norm": 2.6894257068634033,
      "learning_rate": 1.0683582089552238e-05,
      "loss": 0.9803,
      "step": 15100
    },
    {
      "epoch": 6.460652591170826,
      "grad_norm": 2.381917953491211,
      "learning_rate": 1.061961620469083e-05,
      "loss": 0.9372,
      "step": 15150
    },
    {
      "epoch": 6.481979100021326,
      "grad_norm": 3.239283800125122,
      "learning_rate": 1.0555650319829423e-05,
      "loss": 1.0316,
      "step": 15200
    },
    {
      "epoch": 6.481979100021326,
      "eval_loss": 0.96284019947052,
      "eval_runtime": 2.1425,
      "eval_samples_per_second": 461.145,
      "eval_steps_per_second": 57.877,
      "step": 15200
    },
    {
      "epoch": 6.503305608871828,
      "grad_norm": 3.267341375350952,
      "learning_rate": 1.0491684434968016e-05,
      "loss": 1.0017,
      "step": 15250
    },
    {
      "epoch": 6.524632117722329,
      "grad_norm": 3.5981132984161377,
      "learning_rate": 1.0427718550106609e-05,
      "loss": 1.0099,
      "step": 15300
    },
    {
      "epoch": 6.54595862657283,
      "grad_norm": 1.9932830333709717,
      "learning_rate": 1.0363752665245202e-05,
      "loss": 0.9277,
      "step": 15350
    },
    {
      "epoch": 6.567285135423331,
      "grad_norm": 1.7583590745925903,
      "learning_rate": 1.0299786780383795e-05,
      "loss": 0.9317,
      "step": 15400
    },
    {
      "epoch": 6.567285135423331,
      "eval_loss": 0.965669572353363,
      "eval_runtime": 2.1496,
      "eval_samples_per_second": 459.63,
      "eval_steps_per_second": 57.686,
      "step": 15400
    },
    {
      "epoch": 6.588611644273833,
      "grad_norm": 2.874379873275757,
      "learning_rate": 1.0235820895522388e-05,
      "loss": 0.9439,
      "step": 15450
    },
    {
      "epoch": 6.609938153124333,
      "grad_norm": 3.012794017791748,
      "learning_rate": 1.017185501066098e-05,
      "loss": 0.9342,
      "step": 15500
    },
    {
      "epoch": 6.631264661974835,
      "grad_norm": 2.467029571533203,
      "learning_rate": 1.0107889125799573e-05,
      "loss": 0.9286,
      "step": 15550
    },
    {
      "epoch": 6.652591170825336,
      "grad_norm": 3.41434907913208,
      "learning_rate": 1.0043923240938166e-05,
      "loss": 0.9325,
      "step": 15600
    },
    {
      "epoch": 6.652591170825336,
      "eval_loss": 0.96478271484375,
      "eval_runtime": 2.1627,
      "eval_samples_per_second": 456.843,
      "eval_steps_per_second": 57.337,
      "step": 15600
    },
    {
      "epoch": 6.673917679675837,
      "grad_norm": 2.0483546257019043,
      "learning_rate": 9.979957356076759e-06,
      "loss": 0.9643,
      "step": 15650
    },
    {
      "epoch": 6.695244188526338,
      "grad_norm": 3.2502074241638184,
      "learning_rate": 9.915991471215352e-06,
      "loss": 0.9764,
      "step": 15700
    },
    {
      "epoch": 6.71657069737684,
      "grad_norm": 2.4275283813476562,
      "learning_rate": 9.852025586353945e-06,
      "loss": 0.8738,
      "step": 15750
    },
    {
      "epoch": 6.73789720622734,
      "grad_norm": 3.16336727142334,
      "learning_rate": 9.788059701492538e-06,
      "loss": 0.9258,
      "step": 15800
    },
    {
      "epoch": 6.73789720622734,
      "eval_loss": 0.9688470959663391,
      "eval_runtime": 2.137,
      "eval_samples_per_second": 462.341,
      "eval_steps_per_second": 58.027,
      "step": 15800
    },
    {
      "epoch": 6.759223715077842,
      "grad_norm": 2.230821371078491,
      "learning_rate": 9.72409381663113e-06,
      "loss": 0.9542,
      "step": 15850
    },
    {
      "epoch": 6.780550223928343,
      "grad_norm": 1.7460029125213623,
      "learning_rate": 9.660127931769723e-06,
      "loss": 0.9359,
      "step": 15900
    },
    {
      "epoch": 6.801876732778844,
      "grad_norm": 3.4300765991210938,
      "learning_rate": 9.596162046908316e-06,
      "loss": 0.9922,
      "step": 15950
    },
    {
      "epoch": 6.823203241629345,
      "grad_norm": 2.36191725730896,
      "learning_rate": 9.532196162046909e-06,
      "loss": 0.9943,
      "step": 16000
    },
    {
      "epoch": 6.823203241629345,
      "eval_loss": 0.9610512256622314,
      "eval_runtime": 2.0437,
      "eval_samples_per_second": 483.437,
      "eval_steps_per_second": 60.674,
      "step": 16000
    },
    {
      "epoch": 6.844529750479847,
      "grad_norm": 2.8157825469970703,
      "learning_rate": 9.468230277185502e-06,
      "loss": 0.9725,
      "step": 16050
    },
    {
      "epoch": 6.865856259330347,
      "grad_norm": 4.721852779388428,
      "learning_rate": 9.404264392324095e-06,
      "loss": 0.9722,
      "step": 16100
    },
    {
      "epoch": 6.887182768180849,
      "grad_norm": 2.2427279949188232,
      "learning_rate": 9.340298507462687e-06,
      "loss": 0.9259,
      "step": 16150
    },
    {
      "epoch": 6.90850927703135,
      "grad_norm": 2.6474294662475586,
      "learning_rate": 9.27633262260128e-06,
      "loss": 0.9047,
      "step": 16200
    },
    {
      "epoch": 6.90850927703135,
      "eval_loss": 0.9607556462287903,
      "eval_runtime": 2.0354,
      "eval_samples_per_second": 485.416,
      "eval_steps_per_second": 60.923,
      "step": 16200
    },
    {
      "epoch": 6.929835785881851,
      "grad_norm": 1.8369717597961426,
      "learning_rate": 9.212366737739873e-06,
      "loss": 1.0362,
      "step": 16250
    },
    {
      "epoch": 6.951162294732352,
      "grad_norm": 2.501025915145874,
      "learning_rate": 9.148400852878466e-06,
      "loss": 0.9892,
      "step": 16300
    },
    {
      "epoch": 6.972488803582854,
      "grad_norm": 1.8297553062438965,
      "learning_rate": 9.084434968017059e-06,
      "loss": 0.9781,
      "step": 16350
    },
    {
      "epoch": 6.993815312433354,
      "grad_norm": 3.491442918777466,
      "learning_rate": 9.020469083155652e-06,
      "loss": 0.9196,
      "step": 16400
    },
    {
      "epoch": 6.993815312433354,
      "eval_loss": 0.9618147015571594,
      "eval_runtime": 2.0525,
      "eval_samples_per_second": 481.363,
      "eval_steps_per_second": 60.414,
      "step": 16400
    },
    {
      "epoch": 7.0149285561953505,
      "grad_norm": 2.6252694129943848,
      "learning_rate": 8.956503198294243e-06,
      "loss": 0.9164,
      "step": 16450
    },
    {
      "epoch": 7.036255065045852,
      "grad_norm": 1.6579362154006958,
      "learning_rate": 8.892537313432836e-06,
      "loss": 0.9388,
      "step": 16500
    },
    {
      "epoch": 7.057581573896353,
      "grad_norm": 3.3008525371551514,
      "learning_rate": 8.828571428571429e-06,
      "loss": 0.949,
      "step": 16550
    },
    {
      "epoch": 7.078908082746854,
      "grad_norm": 3.266209363937378,
      "learning_rate": 8.764605543710021e-06,
      "loss": 0.9339,
      "step": 16600
    },
    {
      "epoch": 7.078908082746854,
      "eval_loss": 0.9615347385406494,
      "eval_runtime": 2.0581,
      "eval_samples_per_second": 480.045,
      "eval_steps_per_second": 60.249,
      "step": 16600
    },
    {
      "epoch": 7.1002345915973555,
      "grad_norm": 2.6554858684539795,
      "learning_rate": 8.700639658848614e-06,
      "loss": 0.9738,
      "step": 16650
    },
    {
      "epoch": 7.121561100447857,
      "grad_norm": 2.0172951221466064,
      "learning_rate": 8.636673773987207e-06,
      "loss": 0.9956,
      "step": 16700
    },
    {
      "epoch": 7.1428876092983575,
      "grad_norm": 2.582977294921875,
      "learning_rate": 8.5727078891258e-06,
      "loss": 0.9487,
      "step": 16750
    },
    {
      "epoch": 7.164214118148859,
      "grad_norm": 4.676946640014648,
      "learning_rate": 8.508742004264393e-06,
      "loss": 0.9713,
      "step": 16800
    },
    {
      "epoch": 7.164214118148859,
      "eval_loss": 0.9603316187858582,
      "eval_runtime": 2.041,
      "eval_samples_per_second": 484.072,
      "eval_steps_per_second": 60.754,
      "step": 16800
    },
    {
      "epoch": 7.1855406269993605,
      "grad_norm": 2.7295126914978027,
      "learning_rate": 8.444776119402986e-06,
      "loss": 0.9085,
      "step": 16850
    },
    {
      "epoch": 7.206867135849861,
      "grad_norm": 3.315983295440674,
      "learning_rate": 8.380810234541578e-06,
      "loss": 0.9588,
      "step": 16900
    },
    {
      "epoch": 7.2281936447003625,
      "grad_norm": 3.8666129112243652,
      "learning_rate": 8.316844349680171e-06,
      "loss": 0.9204,
      "step": 16950
    },
    {
      "epoch": 7.249520153550864,
      "grad_norm": 2.4360506534576416,
      "learning_rate": 8.252878464818764e-06,
      "loss": 0.9545,
      "step": 17000
    },
    {
      "epoch": 7.249520153550864,
      "eval_loss": 0.9626766443252563,
      "eval_runtime": 2.0406,
      "eval_samples_per_second": 484.17,
      "eval_steps_per_second": 60.766,
      "step": 17000
    },
    {
      "epoch": 7.270846662401365,
      "grad_norm": 3.93310809135437,
      "learning_rate": 8.188912579957357e-06,
      "loss": 1.0135,
      "step": 17050
    },
    {
      "epoch": 7.292173171251866,
      "grad_norm": 2.4600913524627686,
      "learning_rate": 8.124946695095948e-06,
      "loss": 0.9194,
      "step": 17100
    },
    {
      "epoch": 7.3134996801023675,
      "grad_norm": 3.702836513519287,
      "learning_rate": 8.060980810234541e-06,
      "loss": 0.913,
      "step": 17150
    },
    {
      "epoch": 7.334826188952868,
      "grad_norm": 1.9498178958892822,
      "learning_rate": 7.997014925373134e-06,
      "loss": 1.0122,
      "step": 17200
    },
    {
      "epoch": 7.334826188952868,
      "eval_loss": 0.9610747694969177,
      "eval_runtime": 2.0622,
      "eval_samples_per_second": 479.106,
      "eval_steps_per_second": 60.131,
      "step": 17200
    },
    {
      "epoch": 7.3561526978033696,
      "grad_norm": 2.035245656967163,
      "learning_rate": 7.933049040511727e-06,
      "loss": 0.9502,
      "step": 17250
    },
    {
      "epoch": 7.377479206653871,
      "grad_norm": 2.444373607635498,
      "learning_rate": 7.86908315565032e-06,
      "loss": 0.9628,
      "step": 17300
    },
    {
      "epoch": 7.398805715504372,
      "grad_norm": 1.9655283689498901,
      "learning_rate": 7.805117270788912e-06,
      "loss": 0.9199,
      "step": 17350
    },
    {
      "epoch": 7.420132224354873,
      "grad_norm": 2.5890414714813232,
      "learning_rate": 7.741151385927505e-06,
      "loss": 0.9697,
      "step": 17400
    },
    {
      "epoch": 7.420132224354873,
      "eval_loss": 0.9619036912918091,
      "eval_runtime": 2.0414,
      "eval_samples_per_second": 483.974,
      "eval_steps_per_second": 60.742,
      "step": 17400
    },
    {
      "epoch": 7.4414587332053745,
      "grad_norm": 3.5432000160217285,
      "learning_rate": 7.677185501066098e-06,
      "loss": 0.9163,
      "step": 17450
    },
    {
      "epoch": 7.462785242055875,
      "grad_norm": 2.899266242980957,
      "learning_rate": 7.613219616204692e-06,
      "loss": 0.9724,
      "step": 17500
    },
    {
      "epoch": 7.484111750906377,
      "grad_norm": 2.7138044834136963,
      "learning_rate": 7.5492537313432845e-06,
      "loss": 0.9121,
      "step": 17550
    },
    {
      "epoch": 7.505438259756878,
      "grad_norm": 2.3532397747039795,
      "learning_rate": 7.4852878464818765e-06,
      "loss": 0.9106,
      "step": 17600
    },
    {
      "epoch": 7.505438259756878,
      "eval_loss": 0.9642152190208435,
      "eval_runtime": 2.0237,
      "eval_samples_per_second": 488.208,
      "eval_steps_per_second": 61.273,
      "step": 17600
    },
    {
      "epoch": 7.526764768607379,
      "grad_norm": 2.186344861984253,
      "learning_rate": 7.4213219616204685e-06,
      "loss": 0.9606,
      "step": 17650
    },
    {
      "epoch": 7.54809127745788,
      "grad_norm": NaN,
      "learning_rate": 7.357356076759061e-06,
      "loss": 0.9631,
      "step": 17700
    },
    {
      "epoch": 7.569417786308382,
      "grad_norm": 3.0812973976135254,
      "learning_rate": 7.293390191897654e-06,
      "loss": 0.9509,
      "step": 17750
    },
    {
      "epoch": 7.590744295158882,
      "grad_norm": 3.0781991481781006,
      "learning_rate": 7.229424307036247e-06,
      "loss": 0.8787,
      "step": 17800
    },
    {
      "epoch": 7.590744295158882,
      "eval_loss": 0.9608345627784729,
      "eval_runtime": 2.0424,
      "eval_samples_per_second": 483.741,
      "eval_steps_per_second": 60.712,
      "step": 17800
    },
    {
      "epoch": 7.612070804009384,
      "grad_norm": 2.548438310623169,
      "learning_rate": 7.16545842217484e-06,
      "loss": 0.9681,
      "step": 17850
    },
    {
      "epoch": 7.633397312859885,
      "grad_norm": 3.026308059692383,
      "learning_rate": 7.101492537313433e-06,
      "loss": 0.9227,
      "step": 17900
    },
    {
      "epoch": 7.654723821710386,
      "grad_norm": 2.828280448913574,
      "learning_rate": 7.0375266524520256e-06,
      "loss": 0.9398,
      "step": 17950
    },
    {
      "epoch": 7.676050330560887,
      "grad_norm": 2.0655100345611572,
      "learning_rate": 6.973560767590618e-06,
      "loss": 0.9586,
      "step": 18000
    },
    {
      "epoch": 7.676050330560887,
      "eval_loss": 0.9582422375679016,
      "eval_runtime": 2.0539,
      "eval_samples_per_second": 481.026,
      "eval_steps_per_second": 60.372,
      "step": 18000
    },
    {
      "epoch": 7.697376839411389,
      "grad_norm": 2.771817207336426,
      "learning_rate": 6.909594882729211e-06,
      "loss": 0.8866,
      "step": 18050
    },
    {
      "epoch": 7.718703348261889,
      "grad_norm": 1.975346326828003,
      "learning_rate": 6.845628997867804e-06,
      "loss": 0.9412,
      "step": 18100
    },
    {
      "epoch": 7.740029857112391,
      "grad_norm": 2.169585943222046,
      "learning_rate": 6.781663113006397e-06,
      "loss": 1.0011,
      "step": 18150
    },
    {
      "epoch": 7.761356365962892,
      "grad_norm": 3.644899845123291,
      "learning_rate": 6.71769722814499e-06,
      "loss": 0.966,
      "step": 18200
    },
    {
      "epoch": 7.761356365962892,
      "eval_loss": 0.9587649703025818,
      "eval_runtime": 2.0211,
      "eval_samples_per_second": 488.845,
      "eval_steps_per_second": 61.353,
      "step": 18200
    },
    {
      "epoch": 7.782682874813393,
      "grad_norm": 2.7380058765411377,
      "learning_rate": 6.653731343283583e-06,
      "loss": 0.8966,
      "step": 18250
    },
    {
      "epoch": 7.804009383663894,
      "grad_norm": 2.649491310119629,
      "learning_rate": 6.5897654584221755e-06,
      "loss": 0.8891,
      "step": 18300
    },
    {
      "epoch": 7.825335892514396,
      "grad_norm": 2.7699027061462402,
      "learning_rate": 6.525799573560768e-06,
      "loss": 0.8816,
      "step": 18350
    },
    {
      "epoch": 7.846662401364896,
      "grad_norm": 11.77096176147461,
      "learning_rate": 6.461833688699361e-06,
      "loss": 0.9506,
      "step": 18400
    },
    {
      "epoch": 7.846662401364896,
      "eval_loss": 0.9613710641860962,
      "eval_runtime": 2.0718,
      "eval_samples_per_second": 476.891,
      "eval_steps_per_second": 59.853,
      "step": 18400
    },
    {
      "epoch": 7.867988910215398,
      "grad_norm": 3.3644323348999023,
      "learning_rate": 6.397867803837953e-06,
      "loss": 0.9279,
      "step": 18450
    },
    {
      "epoch": 7.889315419065899,
      "grad_norm": 2.263066053390503,
      "learning_rate": 6.333901918976546e-06,
      "loss": 0.9455,
      "step": 18500
    },
    {
      "epoch": 7.9106419279164,
      "grad_norm": 2.7522428035736084,
      "learning_rate": 6.269936034115139e-06,
      "loss": 0.9711,
      "step": 18550
    },
    {
      "epoch": 7.931968436766901,
      "grad_norm": 2.140137195587158,
      "learning_rate": 6.205970149253732e-06,
      "loss": 0.8756,
      "step": 18600
    },
    {
      "epoch": 7.931968436766901,
      "eval_loss": 0.9596876502037048,
      "eval_runtime": 2.0584,
      "eval_samples_per_second": 479.993,
      "eval_steps_per_second": 60.242,
      "step": 18600
    },
    {
      "epoch": 7.953294945617403,
      "grad_norm": 1.8170585632324219,
      "learning_rate": 6.1420042643923245e-06,
      "loss": 0.9469,
      "step": 18650
    },
    {
      "epoch": 7.974621454467903,
      "grad_norm": 2.215895414352417,
      "learning_rate": 6.0780383795309165e-06,
      "loss": 0.9281,
      "step": 18700
    },
    {
      "epoch": 7.995947963318405,
      "grad_norm": 2.925154447555542,
      "learning_rate": 6.014072494669509e-06,
      "loss": 0.9263,
      "step": 18750
    },
    {
      "epoch": 8.0170612070804,
      "grad_norm": 1.6544923782348633,
      "learning_rate": 5.950106609808102e-06,
      "loss": 0.8663,
      "step": 18800
    },
    {
      "epoch": 8.0170612070804,
      "eval_loss": 0.9601651430130005,
      "eval_runtime": 2.0407,
      "eval_samples_per_second": 484.137,
      "eval_steps_per_second": 60.762,
      "step": 18800
    },
    {
      "epoch": 8.038387715930902,
      "grad_norm": 2.02691650390625,
      "learning_rate": 5.886140724946695e-06,
      "loss": 1.0121,
      "step": 18850
    },
    {
      "epoch": 8.059714224781404,
      "grad_norm": 4.00295352935791,
      "learning_rate": 5.822174840085288e-06,
      "loss": 0.9052,
      "step": 18900
    },
    {
      "epoch": 8.081040733631905,
      "grad_norm": 3.2680253982543945,
      "learning_rate": 5.758208955223881e-06,
      "loss": 0.9879,
      "step": 18950
    },
    {
      "epoch": 8.102367242482405,
      "grad_norm": 2.8097903728485107,
      "learning_rate": 5.6942430703624736e-06,
      "loss": 0.9611,
      "step": 19000
    },
    {
      "epoch": 8.102367242482405,
      "eval_loss": 0.959801197052002,
      "eval_runtime": 2.0254,
      "eval_samples_per_second": 487.808,
      "eval_steps_per_second": 61.223,
      "step": 19000
    },
    {
      "epoch": 8.123693751332906,
      "grad_norm": 2.680861473083496,
      "learning_rate": 5.630277185501066e-06,
      "loss": 0.9149,
      "step": 19050
    },
    {
      "epoch": 8.145020260183408,
      "grad_norm": 1.5664292573928833,
      "learning_rate": 5.566311300639659e-06,
      "loss": 0.9248,
      "step": 19100
    },
    {
      "epoch": 8.16634676903391,
      "grad_norm": 2.852492332458496,
      "learning_rate": 5.502345415778252e-06,
      "loss": 0.8519,
      "step": 19150
    },
    {
      "epoch": 8.18767327788441,
      "grad_norm": 2.7174408435821533,
      "learning_rate": 5.438379530916844e-06,
      "loss": 0.9959,
      "step": 19200
    },
    {
      "epoch": 8.18767327788441,
      "eval_loss": 0.9578889608383179,
      "eval_runtime": 2.0361,
      "eval_samples_per_second": 485.237,
      "eval_steps_per_second": 60.9,
      "step": 19200
    },
    {
      "epoch": 8.208999786734912,
      "grad_norm": 2.49923038482666,
      "learning_rate": 5.374413646055437e-06,
      "loss": 0.9543,
      "step": 19250
    },
    {
      "epoch": 8.230326295585412,
      "grad_norm": 1.8625348806381226,
      "learning_rate": 5.31044776119403e-06,
      "loss": 0.9174,
      "step": 19300
    },
    {
      "epoch": 8.251652804435913,
      "grad_norm": 3.3423690795898438,
      "learning_rate": 5.246481876332623e-06,
      "loss": 0.9963,
      "step": 19350
    },
    {
      "epoch": 8.272979313286415,
      "grad_norm": 2.6883065700531006,
      "learning_rate": 5.1825159914712155e-06,
      "loss": 0.9364,
      "step": 19400
    },
    {
      "epoch": 8.272979313286415,
      "eval_loss": 0.9581241011619568,
      "eval_runtime": 2.0393,
      "eval_samples_per_second": 484.473,
      "eval_steps_per_second": 60.804,
      "step": 19400
    },
    {
      "epoch": 8.294305822136916,
      "grad_norm": 2.585963010787964,
      "learning_rate": 5.118550106609808e-06,
      "loss": 0.8696,
      "step": 19450
    },
    {
      "epoch": 8.315632330987418,
      "grad_norm": 3.6013336181640625,
      "learning_rate": 5.054584221748401e-06,
      "loss": 0.9416,
      "step": 19500
    },
    {
      "epoch": 8.33695883983792,
      "grad_norm": 3.1506237983703613,
      "learning_rate": 4.990618336886994e-06,
      "loss": 0.8771,
      "step": 19550
    },
    {
      "epoch": 8.358285348688419,
      "grad_norm": 1.863676905632019,
      "learning_rate": 4.926652452025587e-06,
      "loss": 0.8423,
      "step": 19600
    },
    {
      "epoch": 8.358285348688419,
      "eval_loss": 0.9605115056037903,
      "eval_runtime": 2.0413,
      "eval_samples_per_second": 484.001,
      "eval_steps_per_second": 60.745,
      "step": 19600
    },
    {
      "epoch": 8.37961185753892,
      "grad_norm": 2.570357322692871,
      "learning_rate": 4.86268656716418e-06,
      "loss": 0.9184,
      "step": 19650
    },
    {
      "epoch": 8.400938366389422,
      "grad_norm": 1.9406042098999023,
      "learning_rate": 4.7987206823027725e-06,
      "loss": 0.9448,
      "step": 19700
    },
    {
      "epoch": 8.422264875239923,
      "grad_norm": 3.6600000858306885,
      "learning_rate": 4.7347547974413645e-06,
      "loss": 0.931,
      "step": 19750
    },
    {
      "epoch": 8.443591384090425,
      "grad_norm": 2.3453240394592285,
      "learning_rate": 4.670788912579957e-06,
      "loss": 0.9199,
      "step": 19800
    },
    {
      "epoch": 8.443591384090425,
      "eval_loss": 0.9572390913963318,
      "eval_runtime": 2.029,
      "eval_samples_per_second": 486.932,
      "eval_steps_per_second": 61.113,
      "step": 19800
    },
    {
      "epoch": 8.464917892940926,
      "grad_norm": 2.1978046894073486,
      "learning_rate": 4.60682302771855e-06,
      "loss": 0.9156,
      "step": 19850
    },
    {
      "epoch": 8.486244401791426,
      "grad_norm": 1.6230388879776,
      "learning_rate": 4.542857142857143e-06,
      "loss": 0.926,
      "step": 19900
    },
    {
      "epoch": 8.507570910641927,
      "grad_norm": 3.8687965869903564,
      "learning_rate": 4.478891257995736e-06,
      "loss": 0.9032,
      "step": 19950
    },
    {
      "epoch": 8.528897419492429,
      "grad_norm": 3.194051742553711,
      "learning_rate": 4.414925373134328e-06,
      "loss": 0.9602,
      "step": 20000
    },
    {
      "epoch": 8.528897419492429,
      "eval_loss": 0.9573689699172974,
      "eval_runtime": 2.0388,
      "eval_samples_per_second": 484.604,
      "eval_steps_per_second": 60.821,
      "step": 20000
    },
    {
      "epoch": 8.55022392834293,
      "grad_norm": 2.4272632598876953,
      "learning_rate": 4.350959488272921e-06,
      "loss": 0.9588,
      "step": 20050
    },
    {
      "epoch": 8.571550437193432,
      "grad_norm": 2.646167039871216,
      "learning_rate": 4.2869936034115136e-06,
      "loss": 0.9487,
      "step": 20100
    },
    {
      "epoch": 8.592876946043933,
      "grad_norm": 2.103386640548706,
      "learning_rate": 4.223027718550106e-06,
      "loss": 0.8981,
      "step": 20150
    },
    {
      "epoch": 8.614203454894433,
      "grad_norm": 3.8903183937072754,
      "learning_rate": 4.159061833688699e-06,
      "loss": 1.0029,
      "step": 20200
    },
    {
      "epoch": 8.614203454894433,
      "eval_loss": 0.9574841260910034,
      "eval_runtime": 2.0385,
      "eval_samples_per_second": 484.68,
      "eval_steps_per_second": 60.83,
      "step": 20200
    },
    {
      "epoch": 8.635529963744935,
      "grad_norm": 2.192203998565674,
      "learning_rate": 4.095095948827292e-06,
      "loss": 0.9632,
      "step": 20250
    },
    {
      "epoch": 8.656856472595436,
      "grad_norm": 2.7998604774475098,
      "learning_rate": 4.031130063965885e-06,
      "loss": 0.9168,
      "step": 20300
    },
    {
      "epoch": 8.678182981445937,
      "grad_norm": 2.8576529026031494,
      "learning_rate": 3.967164179104478e-06,
      "loss": 0.9361,
      "step": 20350
    },
    {
      "epoch": 8.699509490296439,
      "grad_norm": 4.270773887634277,
      "learning_rate": 3.903198294243071e-06,
      "loss": 0.9145,
      "step": 20400
    },
    {
      "epoch": 8.699509490296439,
      "eval_loss": 0.9570295214653015,
      "eval_runtime": 2.0462,
      "eval_samples_per_second": 482.848,
      "eval_steps_per_second": 60.6,
      "step": 20400
    },
    {
      "epoch": 8.72083599914694,
      "grad_norm": 2.58953595161438,
      "learning_rate": 3.8392324093816635e-06,
      "loss": 0.8979,
      "step": 20450
    },
    {
      "epoch": 8.74216250799744,
      "grad_norm": 3.3224036693573,
      "learning_rate": 3.7752665245202563e-06,
      "loss": 0.9553,
      "step": 20500
    },
    {
      "epoch": 8.763489016847942,
      "grad_norm": 3.3334295749664307,
      "learning_rate": 3.7113006396588487e-06,
      "loss": 0.8567,
      "step": 20550
    },
    {
      "epoch": 8.784815525698443,
      "grad_norm": 2.6727960109710693,
      "learning_rate": 3.647334754797441e-06,
      "loss": 0.9177,
      "step": 20600
    },
    {
      "epoch": 8.784815525698443,
      "eval_loss": 0.9576728343963623,
      "eval_runtime": 2.0627,
      "eval_samples_per_second": 478.989,
      "eval_steps_per_second": 60.116,
      "step": 20600
    },
    {
      "epoch": 8.806142034548945,
      "grad_norm": 2.4300479888916016,
      "learning_rate": 3.583368869936034e-06,
      "loss": 0.9236,
      "step": 20650
    },
    {
      "epoch": 8.827468543399446,
      "grad_norm": 3.3929829597473145,
      "learning_rate": 3.519402985074627e-06,
      "loss": 0.9957,
      "step": 20700
    },
    {
      "epoch": 8.848795052249947,
      "grad_norm": 2.2158946990966797,
      "learning_rate": 3.4554371002132197e-06,
      "loss": 0.9955,
      "step": 20750
    },
    {
      "epoch": 8.870121561100447,
      "grad_norm": 1.6910569667816162,
      "learning_rate": 3.3914712153518125e-06,
      "loss": 0.9873,
      "step": 20800
    },
    {
      "epoch": 8.870121561100447,
      "eval_loss": 0.9566768407821655,
      "eval_runtime": 2.038,
      "eval_samples_per_second": 484.789,
      "eval_steps_per_second": 60.844,
      "step": 20800
    },
    {
      "epoch": 8.891448069950949,
      "grad_norm": 2.3308136463165283,
      "learning_rate": 3.3275053304904054e-06,
      "loss": 0.9342,
      "step": 20850
    },
    {
      "epoch": 8.91277457880145,
      "grad_norm": 2.2958874702453613,
      "learning_rate": 3.263539445628998e-06,
      "loss": 0.9592,
      "step": 20900
    },
    {
      "epoch": 8.934101087651952,
      "grad_norm": 3.091386318206787,
      "learning_rate": 3.1995735607675906e-06,
      "loss": 0.9335,
      "step": 20950
    },
    {
      "epoch": 8.955427596502453,
      "grad_norm": 3.262568950653076,
      "learning_rate": 3.1356076759061835e-06,
      "loss": 1.0003,
      "step": 21000
    },
    {
      "epoch": 8.955427596502453,
      "eval_loss": 0.9577902555465698,
      "eval_runtime": 2.0346,
      "eval_samples_per_second": 485.601,
      "eval_steps_per_second": 60.946,
      "step": 21000
    },
    {
      "epoch": 8.976754105352954,
      "grad_norm": 3.4106667041778564,
      "learning_rate": 3.0716417910447763e-06,
      "loss": 0.9842,
      "step": 21050
    },
    {
      "epoch": 8.998080614203454,
      "grad_norm": 2.673859119415283,
      "learning_rate": 3.0076759061833687e-06,
      "loss": 0.8692,
      "step": 21100
    },
    {
      "epoch": 9.019193857965451,
      "grad_norm": 2.102918863296509,
      "learning_rate": 2.9437100213219616e-06,
      "loss": 0.9625,
      "step": 21150
    },
    {
      "epoch": 9.040520366815953,
      "grad_norm": 1.8136988878250122,
      "learning_rate": 2.8797441364605544e-06,
      "loss": 0.981,
      "step": 21200
    },
    {
      "epoch": 9.040520366815953,
      "eval_loss": 0.9562001824378967,
      "eval_runtime": 2.0361,
      "eval_samples_per_second": 485.236,
      "eval_steps_per_second": 60.9,
      "step": 21200
    },
    {
      "epoch": 9.061846875666454,
      "grad_norm": 5.224184036254883,
      "learning_rate": 2.8157782515991473e-06,
      "loss": 0.9143,
      "step": 21250
    },
    {
      "epoch": 9.083173384516954,
      "grad_norm": 3.7825534343719482,
      "learning_rate": 2.75181236673774e-06,
      "loss": 0.9735,
      "step": 21300
    },
    {
      "epoch": 9.104499893367455,
      "grad_norm": 3.7381691932678223,
      "learning_rate": 2.6878464818763325e-06,
      "loss": 0.8949,
      "step": 21350
    },
    {
      "epoch": 9.125826402217957,
      "grad_norm": 4.177989482879639,
      "learning_rate": 2.6238805970149254e-06,
      "loss": 0.9912,
      "step": 21400
    },
    {
      "epoch": 9.125826402217957,
      "eval_loss": 0.9558994770050049,
      "eval_runtime": 2.0543,
      "eval_samples_per_second": 480.938,
      "eval_steps_per_second": 60.361,
      "step": 21400
    },
    {
      "epoch": 9.147152911068458,
      "grad_norm": 3.3462626934051514,
      "learning_rate": 2.559914712153518e-06,
      "loss": 0.8885,
      "step": 21450
    },
    {
      "epoch": 9.16847941991896,
      "grad_norm": 2.2875142097473145,
      "learning_rate": 2.495948827292111e-06,
      "loss": 0.934,
      "step": 21500
    },
    {
      "epoch": 9.189805928769461,
      "grad_norm": 3.1160664558410645,
      "learning_rate": 2.431982942430704e-06,
      "loss": 0.9556,
      "step": 21550
    },
    {
      "epoch": 9.21113243761996,
      "grad_norm": 1.9717360734939575,
      "learning_rate": 2.3680170575692963e-06,
      "loss": 0.9551,
      "step": 21600
    },
    {
      "epoch": 9.21113243761996,
      "eval_loss": 0.9564942717552185,
      "eval_runtime": 2.0379,
      "eval_samples_per_second": 484.816,
      "eval_steps_per_second": 60.847,
      "step": 21600
    },
    {
      "epoch": 9.232458946470462,
      "grad_norm": 2.6781013011932373,
      "learning_rate": 2.304051172707889e-06,
      "loss": 0.8968,
      "step": 21650
    },
    {
      "epoch": 9.253785455320964,
      "grad_norm": 3.2061920166015625,
      "learning_rate": 2.240085287846482e-06,
      "loss": 0.9784,
      "step": 21700
    },
    {
      "epoch": 9.275111964171465,
      "grad_norm": 2.9922266006469727,
      "learning_rate": 2.1761194029850744e-06,
      "loss": 0.8676,
      "step": 21750
    },
    {
      "epoch": 9.296438473021967,
      "grad_norm": 2.7137856483459473,
      "learning_rate": 2.1121535181236673e-06,
      "loss": 0.8771,
      "step": 21800
    },
    {
      "epoch": 9.296438473021967,
      "eval_loss": 0.9586938619613647,
      "eval_runtime": 2.032,
      "eval_samples_per_second": 486.226,
      "eval_steps_per_second": 61.024,
      "step": 21800
    },
    {
      "epoch": 9.317764981872468,
      "grad_norm": 1.9188421964645386,
      "learning_rate": 2.04818763326226e-06,
      "loss": 0.9397,
      "step": 21850
    },
    {
      "epoch": 9.339091490722968,
      "grad_norm": 2.445046901702881,
      "learning_rate": 1.984221748400853e-06,
      "loss": 0.9871,
      "step": 21900
    },
    {
      "epoch": 9.36041799957347,
      "grad_norm": 3.2858190536499023,
      "learning_rate": 1.920255863539446e-06,
      "loss": 0.9882,
      "step": 21950
    },
    {
      "epoch": 9.38174450842397,
      "grad_norm": 2.6079325675964355,
      "learning_rate": 1.8562899786780384e-06,
      "loss": 0.8833,
      "step": 22000
    },
    {
      "epoch": 9.38174450842397,
      "eval_loss": 0.9579164981842041,
      "eval_runtime": 2.0661,
      "eval_samples_per_second": 478.199,
      "eval_steps_per_second": 60.017,
      "step": 22000
    },
    {
      "epoch": 9.403071017274472,
      "grad_norm": 2.6229801177978516,
      "learning_rate": 1.792324093816631e-06,
      "loss": 0.8973,
      "step": 22050
    },
    {
      "epoch": 9.424397526124974,
      "grad_norm": 2.6764276027679443,
      "learning_rate": 1.7283582089552239e-06,
      "loss": 0.8719,
      "step": 22100
    },
    {
      "epoch": 9.445724034975475,
      "grad_norm": 3.629028797149658,
      "learning_rate": 1.6643923240938167e-06,
      "loss": 0.9149,
      "step": 22150
    },
    {
      "epoch": 9.467050543825975,
      "grad_norm": 2.527571678161621,
      "learning_rate": 1.6004264392324096e-06,
      "loss": 0.9233,
      "step": 22200
    },
    {
      "epoch": 9.467050543825975,
      "eval_loss": 0.9580264687538147,
      "eval_runtime": 2.0617,
      "eval_samples_per_second": 479.214,
      "eval_steps_per_second": 60.144,
      "step": 22200
    },
    {
      "epoch": 9.488377052676476,
      "grad_norm": 2.772911310195923,
      "learning_rate": 1.5364605543710022e-06,
      "loss": 0.9143,
      "step": 22250
    },
    {
      "epoch": 9.509703561526978,
      "grad_norm": 2.4319863319396973,
      "learning_rate": 1.4724946695095948e-06,
      "loss": 0.8865,
      "step": 22300
    },
    {
      "epoch": 9.53103007037748,
      "grad_norm": 3.3123881816864014,
      "learning_rate": 1.4085287846481877e-06,
      "loss": 0.864,
      "step": 22350
    },
    {
      "epoch": 9.55235657922798,
      "grad_norm": 3.0949254035949707,
      "learning_rate": 1.3445628997867805e-06,
      "loss": 0.9481,
      "step": 22400
    },
    {
      "epoch": 9.55235657922798,
      "eval_loss": 0.9579663276672363,
      "eval_runtime": 2.0451,
      "eval_samples_per_second": 483.104,
      "eval_steps_per_second": 60.632,
      "step": 22400
    },
    {
      "epoch": 9.573683088078482,
      "grad_norm": 2.3056094646453857,
      "learning_rate": 1.2805970149253732e-06,
      "loss": 0.9119,
      "step": 22450
    },
    {
      "epoch": 9.595009596928982,
      "grad_norm": 1.9380029439926147,
      "learning_rate": 1.216631130063966e-06,
      "loss": 0.9091,
      "step": 22500
    },
    {
      "epoch": 9.616336105779483,
      "grad_norm": 2.2349541187286377,
      "learning_rate": 1.1526652452025586e-06,
      "loss": 0.9739,
      "step": 22550
    },
    {
      "epoch": 9.637662614629985,
      "grad_norm": 3.2650034427642822,
      "learning_rate": 1.0886993603411515e-06,
      "loss": 0.9809,
      "step": 22600
    },
    {
      "epoch": 9.637662614629985,
      "eval_loss": 0.9572580456733704,
      "eval_runtime": 2.0307,
      "eval_samples_per_second": 486.533,
      "eval_steps_per_second": 61.063,
      "step": 22600
    },
    {
      "epoch": 9.658989123480486,
      "grad_norm": 3.4089131355285645,
      "learning_rate": 1.0247334754797441e-06,
      "loss": 0.8941,
      "step": 22650
    },
    {
      "epoch": 9.680315632330988,
      "grad_norm": 3.2832419872283936,
      "learning_rate": 9.60767590618337e-07,
      "loss": 0.9746,
      "step": 22700
    },
    {
      "epoch": 9.70164214118149,
      "grad_norm": 1.814627766609192,
      "learning_rate": 8.968017057569296e-07,
      "loss": 0.8732,
      "step": 22750
    },
    {
      "epoch": 9.722968650031989,
      "grad_norm": 2.643599033355713,
      "learning_rate": 8.328358208955224e-07,
      "loss": 0.9149,
      "step": 22800
    },
    {
      "epoch": 9.722968650031989,
      "eval_loss": 0.957233190536499,
      "eval_runtime": 2.1538,
      "eval_samples_per_second": 458.721,
      "eval_steps_per_second": 57.572,
      "step": 22800
    },
    {
      "epoch": 9.74429515888249,
      "grad_norm": 2.429102897644043,
      "learning_rate": 7.688699360341152e-07,
      "loss": 0.9866,
      "step": 22850
    },
    {
      "epoch": 9.765621667732992,
      "grad_norm": 2.6325533390045166,
      "learning_rate": 7.049040511727079e-07,
      "loss": 0.9208,
      "step": 22900
    },
    {
      "epoch": 9.786948176583493,
      "grad_norm": 3.0036518573760986,
      "learning_rate": 6.409381663113006e-07,
      "loss": 0.9935,
      "step": 22950
    },
    {
      "epoch": 9.808274685433995,
      "grad_norm": 2.960909843444824,
      "learning_rate": 5.769722814498934e-07,
      "loss": 0.951,
      "step": 23000
    },
    {
      "epoch": 9.808274685433995,
      "eval_loss": 0.9565213322639465,
      "eval_runtime": 2.0131,
      "eval_samples_per_second": 490.788,
      "eval_steps_per_second": 61.597,
      "step": 23000
    },
    {
      "epoch": 9.829601194284496,
      "grad_norm": 2.310194492340088,
      "learning_rate": 5.130063965884861e-07,
      "loss": 0.9274,
      "step": 23050
    },
    {
      "epoch": 9.850927703134996,
      "grad_norm": 2.7789621353149414,
      "learning_rate": 4.490405117270789e-07,
      "loss": 0.9162,
      "step": 23100
    },
    {
      "epoch": 9.872254211985497,
      "grad_norm": 3.174910068511963,
      "learning_rate": 3.850746268656717e-07,
      "loss": 0.9206,
      "step": 23150
    },
    {
      "epoch": 9.893580720835999,
      "grad_norm": 2.214416027069092,
      "learning_rate": 3.211087420042644e-07,
      "loss": 0.9628,
      "step": 23200
    },
    {
      "epoch": 9.893580720835999,
      "eval_loss": 0.9568551778793335,
      "eval_runtime": 2.04,
      "eval_samples_per_second": 484.325,
      "eval_steps_per_second": 60.786,
      "step": 23200
    },
    {
      "epoch": 9.9149072296865,
      "grad_norm": 2.335970878601074,
      "learning_rate": 2.5714285714285716e-07,
      "loss": 0.838,
      "step": 23250
    },
    {
      "epoch": 9.936233738537002,
      "grad_norm": 3.768404483795166,
      "learning_rate": 1.931769722814499e-07,
      "loss": 0.9479,
      "step": 23300
    },
    {
      "epoch": 9.957560247387503,
      "grad_norm": 2.1861019134521484,
      "learning_rate": 1.2921108742004264e-07,
      "loss": 0.9313,
      "step": 23350
    },
    {
      "epoch": 9.978886756238003,
      "grad_norm": 2.6288490295410156,
      "learning_rate": 6.52452025586354e-08,
      "loss": 0.9215,
      "step": 23400
    },
    {
      "epoch": 9.978886756238003,
      "eval_loss": 0.9569934606552124,
      "eval_runtime": 2.0268,
      "eval_samples_per_second": 487.464,
      "eval_steps_per_second": 61.18,
      "step": 23400
    },
    {
      "epoch": 10.0,
      "grad_norm": 5.031373977661133,
      "learning_rate": 1.279317697228145e-09,
      "loss": 0.9243,
      "step": 23450
    }
  ],
  "logging_steps": 50,
  "max_steps": 23450,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6345838716518400.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
